{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd95efc-4d02-47ea-a3ec-ba4acc612963",
   "metadata": {},
   "source": [
    "### BBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f0890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.26.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.26.1-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.7 MB 1.4 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.0/9.7 MB 1.4 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.0/9.7 MB 1.4 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.0/9.7 MB 219.4 kB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.1/9.7 MB 297.7 kB/s eta 0:00:33\n",
      "   ---------------------------------------- 0.1/9.7 MB 245.8 kB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.1/9.7 MB 245.8 kB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.1/9.7 MB 275.8 kB/s eta 0:00:35\n",
      "   ---------------------------------------- 0.1/9.7 MB 297.7 kB/s eta 0:00:33\n",
      "    --------------------------------------- 0.1/9.7 MB 288.8 kB/s eta 0:00:34\n",
      "    --------------------------------------- 0.2/9.7 MB 316.5 kB/s eta 0:00:31\n",
      "    --------------------------------------- 0.2/9.7 MB 316.5 kB/s eta 0:00:31\n",
      "    --------------------------------------- 0.2/9.7 MB 318.1 kB/s eta 0:00:30\n",
      "    --------------------------------------- 0.2/9.7 MB 336.6 kB/s eta 0:00:29\n",
      "    --------------------------------------- 0.2/9.7 MB 336.6 kB/s eta 0:00:29\n",
      "    --------------------------------------- 0.2/9.7 MB 344.1 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.2/9.7 MB 344.1 kB/s eta 0:00:28\n",
      "    --------------------------------------- 0.2/9.7 MB 320.5 kB/s eta 0:00:30\n",
      "   - -------------------------------------- 0.3/9.7 MB 340.9 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.3/9.7 MB 340.9 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.3/9.7 MB 340.9 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.3/9.7 MB 305.2 kB/s eta 0:00:31\n",
      "   - -------------------------------------- 0.3/9.7 MB 333.2 kB/s eta 0:00:29\n",
      "   - -------------------------------------- 0.4/9.7 MB 348.2 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.4/9.7 MB 348.2 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.4/9.7 MB 348.2 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.4/9.7 MB 332.4 kB/s eta 0:00:29\n",
      "   - -------------------------------------- 0.4/9.7 MB 336.4 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.4/9.7 MB 348.5 kB/s eta 0:00:27\n",
      "   - -------------------------------------- 0.5/9.7 MB 356.2 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.5/9.7 MB 356.2 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.5/9.7 MB 356.2 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.5/9.7 MB 346.2 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.5/9.7 MB 345.7 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.5/9.7 MB 356.3 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.5/9.7 MB 347.8 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.5/9.7 MB 347.8 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.6/9.7 MB 359.7 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.6/9.7 MB 365.5 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 0.6/9.7 MB 364.2 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 0.6/9.7 MB 364.2 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 0.6/9.7 MB 364.2 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 0.6/9.7 MB 364.2 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 0.6/9.7 MB 336.0 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 0.7/9.7 MB 349.5 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.7/9.7 MB 349.5 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.7/9.7 MB 353.6 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.7/9.7 MB 353.6 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.7/9.7 MB 353.6 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 0.7/9.7 MB 353.6 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.7/9.7 MB 339.7 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 0.7/9.7 MB 339.7 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 0.7/9.7 MB 339.7 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 0.8/9.7 MB 350.4 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.8/9.7 MB 352.2 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.8/9.7 MB 349.5 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.8/9.7 MB 349.5 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.8/9.7 MB 349.0 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.9/9.7 MB 350.7 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 0.9/9.7 MB 356.4 kB/s eta 0:00:25\n",
      "   --- ------------------------------------ 0.9/9.7 MB 356.0 kB/s eta 0:00:25\n",
      "   --- ------------------------------------ 0.9/9.7 MB 356.0 kB/s eta 0:00:25\n",
      "   --- ------------------------------------ 0.9/9.7 MB 347.0 kB/s eta 0:00:26\n",
      "   --- ------------------------------------ 1.0/9.7 MB 352.3 kB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 357.8 kB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 357.8 kB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 351.5 kB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 361.7 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 361.7 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.1/9.7 MB 362.9 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.1/9.7 MB 362.9 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.1/9.7 MB 362.9 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.1/9.7 MB 360.7 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.1/9.7 MB 363.7 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.2/9.7 MB 363.4 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.2/9.7 MB 364.5 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.2/9.7 MB 364.5 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.2/9.7 MB 364.5 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 1.2/9.7 MB 364.5 kB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 372.8 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 374.1 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 374.1 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 374.1 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 374.1 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 363.2 kB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 367.2 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.4/9.7 MB 374.9 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.4/9.7 MB 374.5 kB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 1.4/9.7 MB 382.3 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 1.5/9.7 MB 384.1 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 1.5/9.7 MB 387.4 kB/s eta 0:00:22\n",
      "   ------ --------------------------------- 1.5/9.7 MB 391.1 kB/s eta 0:00:21\n",
      "   ------ --------------------------------- 1.6/9.7 MB 395.3 kB/s eta 0:00:21\n",
      "   ------ --------------------------------- 1.6/9.7 MB 395.3 kB/s eta 0:00:21\n",
      "   ------ --------------------------------- 1.6/9.7 MB 395.3 kB/s eta 0:00:21\n",
      "   ------ --------------------------------- 1.7/9.7 MB 408.4 kB/s eta 0:00:20\n",
      "   ------ --------------------------------- 1.7/9.7 MB 410.2 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.7/9.7 MB 411.2 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.7/9.7 MB 411.2 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.7/9.7 MB 406.3 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.8/9.7 MB 411.4 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.8/9.7 MB 411.4 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.8/9.7 MB 406.4 kB/s eta 0:00:20\n",
      "   ------- -------------------------------- 1.9/9.7 MB 427.6 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 1.9/9.7 MB 429.3 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 1.9/9.7 MB 429.3 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 1.9/9.7 MB 429.3 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 2.0/9.7 MB 428.7 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 2.0/9.7 MB 436.9 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.1/9.7 MB 441.4 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.1/9.7 MB 442.7 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.1/9.7 MB 444.8 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 2.2/9.7 MB 455.6 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.2/9.7 MB 456.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.2/9.7 MB 456.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.2/9.7 MB 453.7 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.2/9.7 MB 452.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.2/9.7 MB 452.2 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.4/9.7 MB 471.7 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.4/9.7 MB 473.4 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 2.4/9.7 MB 475.9 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 2.4/9.7 MB 475.9 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 2.5/9.7 MB 476.3 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 2.5/9.7 MB 480.2 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 2.5/9.7 MB 480.2 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 2.7/9.7 MB 495.9 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 2.7/9.7 MB 495.9 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 2.7/9.7 MB 492.9 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 2.7/9.7 MB 498.1 kB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 2.8/9.7 MB 500.8 kB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 2.8/9.7 MB 500.8 kB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 2.8/9.7 MB 500.8 kB/s eta 0:00:14\n",
      "   ------------ --------------------------- 2.9/9.7 MB 521.1 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 2.9/9.7 MB 521.1 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 2.9/9.7 MB 521.1 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 3.0/9.7 MB 516.5 kB/s eta 0:00:14\n",
      "   ------------ --------------------------- 3.0/9.7 MB 515.8 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 3.0/9.7 MB 515.8 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 3.0/9.7 MB 515.8 kB/s eta 0:00:13\n",
      "   ------------ --------------------------- 3.0/9.7 MB 511.5 kB/s eta 0:00:14\n",
      "   ------------ --------------------------- 3.1/9.7 MB 511.2 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 3.2/9.7 MB 533.9 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 3.2/9.7 MB 533.9 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 3.2/9.7 MB 532.4 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 3.3/9.7 MB 531.4 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 3.3/9.7 MB 535.6 kB/s eta 0:00:12\n",
      "   ------------- -------------------------- 3.4/9.7 MB 540.1 kB/s eta 0:00:12\n",
      "   ------------- -------------------------- 3.4/9.7 MB 542.1 kB/s eta 0:00:12\n",
      "   ------------- -------------------------- 3.4/9.7 MB 542.1 kB/s eta 0:00:12\n",
      "   -------------- ------------------------- 3.4/9.7 MB 540.2 kB/s eta 0:00:12\n",
      "   -------------- ------------------------- 3.5/9.7 MB 552.6 kB/s eta 0:00:12\n",
      "   -------------- ------------------------- 3.5/9.7 MB 552.6 kB/s eta 0:00:12\n",
      "   -------------- ------------------------- 3.6/9.7 MB 555.6 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 3.7/9.7 MB 559.5 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 3.7/9.7 MB 559.5 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 3.7/9.7 MB 561.8 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 3.8/9.7 MB 568.6 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 3.8/9.7 MB 570.6 kB/s eta 0:00:11\n",
      "   --------------- ------------------------ 3.9/9.7 MB 574.4 kB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 3.9/9.7 MB 582.5 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 4.0/9.7 MB 589.1 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 4.1/9.7 MB 595.3 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 4.1/9.7 MB 595.7 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 4.1/9.7 MB 597.5 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 4.1/9.7 MB 597.5 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 595.4 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 595.4 kB/s eta 0:00:10\n",
      "   ------------------ --------------------- 4.4/9.7 MB 619.2 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 4.4/9.7 MB 619.2 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 4.4/9.7 MB 615.5 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 4.5/9.7 MB 614.3 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 4.5/9.7 MB 618.8 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 4.6/9.7 MB 623.2 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 4.6/9.7 MB 628.8 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 4.7/9.7 MB 636.0 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 4.8/9.7 MB 642.9 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 4.8/9.7 MB 647.1 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 4.9/9.7 MB 652.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 4.9/9.7 MB 652.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 4.9/9.7 MB 652.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.0/9.7 MB 650.0 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.0/9.7 MB 650.0 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 5.2/9.7 MB 676.6 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.2/9.7 MB 676.6 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.3/9.7 MB 675.0 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.3/9.7 MB 675.0 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.3/9.7 MB 669.7 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.3/9.7 MB 669.7 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 5.5/9.7 MB 688.8 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 5.5/9.7 MB 689.9 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 5.6/9.7 MB 696.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.6/9.7 MB 696.1 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.6/9.7 MB 691.9 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.7/9.7 MB 699.3 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.7/9.7 MB 699.3 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.7/9.7 MB 693.8 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.7/9.7 MB 693.8 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 5.7/9.7 MB 693.8 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.0/9.7 MB 710.2 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.1/9.7 MB 717.2 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.1/9.7 MB 719.6 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.1/9.7 MB 719.6 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.1/9.7 MB 715.3 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.2/9.7 MB 716.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.2/9.7 MB 716.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.2/9.7 MB 716.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.2/9.7 MB 710.5 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/9.7 MB 713.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.5/9.7 MB 734.4 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.5/9.7 MB 734.4 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.5/9.7 MB 734.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.6/9.7 MB 733.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.6/9.7 MB 733.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.6/9.7 MB 733.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.6/9.7 MB 724.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.6/9.7 MB 724.4 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 743.9 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 6.9/9.7 MB 751.3 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.0/9.7 MB 758.8 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.0/9.7 MB 754.9 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 756.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 756.2 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 756.2 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.2/9.7 MB 762.8 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.2/9.7 MB 762.8 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.5/9.7 MB 782.4 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.5/9.7 MB 782.4 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.5/9.7 MB 775.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.7/9.7 MB 797.7 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 7.8/9.7 MB 802.3 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 7.9/9.7 MB 809.2 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.0/9.7 MB 817.1 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.0/9.7 MB 818.2 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.1/9.7 MB 823.9 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.1/9.7 MB 823.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.3/9.7 MB 835.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.3/9.7 MB 835.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.6/9.7 MB 862.2 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.6/9.7 MB 862.2 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.6/9.7 MB 862.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.8/9.7 MB 866.5 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.8/9.7 MB 866.5 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.8/9.7 MB 866.5 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.9/9.7 MB 869.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.7 MB 870.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 907.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 907.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 907.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 907.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 896.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 896.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.7 MB 898.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 911.6 kB/s eta 0:00:00\n",
      "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "   ---------------------------------------- 0.0/481.7 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 184.3/481.7 kB 11.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------ 184.3/481.7 kB 11.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 225.3/481.7 kB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 317.4/481.7 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 419.8/481.7 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 481.7/481.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: wsproto, attrs, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-24.2.0 outcome-1.3.0.post0 selenium-4.26.1 trio-0.27.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528f463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "options = webdriver.EdgeOptions()\n",
    "\n",
    "# Load company and crypto names\n",
    "df = pd.read_excel('company_crypto_list.xlsx')  # Your input file with company/crypto names\n",
    "names = df['Name'].dropna().tolist()  # Get the list of names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301d72c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83f960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tesla']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317cc8d-a9f7-4fe7-a263-79015415df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found BBC article for 'Tesla': https://www.bbc.com/news/topics/c8nq32jwjnmt\n",
      "Data saved to 'bbc_articles.xlsx'.\n",
      "Google search and scrape process completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode for better performance\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Load company and crypto names\n",
    "df = pd.read_excel('company_crypto_list.xlsx')\n",
    "names = df['Name'].dropna().tolist()\n",
    "\n",
    "# Initialize a list to store article data\n",
    "article_data = []\n",
    "\n",
    "\n",
    "# Function to search, click the first link, scrape data, and close the browser\n",
    "def search_and_scrape(name, news_site):\n",
    "    try:\n",
    "        service = Service(executable_path=msedgedriver_path)\n",
    "        driver = webdriver.Edge(service=service, options=options)\n",
    "        driver.set_page_load_timeout(15)  # Set a page load timeout\n",
    "        search_query = f\"{news_site} {name}\"\n",
    "        search_url = f\"https://www.google.com/search?q={search_query}\"\n",
    "\n",
    "        driver.get(search_url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Locate the results and find \"bbc.com\" link\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \"div.g\")\n",
    "        found_bbc_link = False\n",
    "\n",
    "        for result in results:\n",
    "            try:\n",
    "                cite_element = result.find_element(By.TAG_NAME, \"cite\")\n",
    "                if \"bbc.com\" in cite_element.text:\n",
    "                    link = result.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                    print(f\"Found BBC article for '{name}': {link}\")\n",
    "                    driver.get(link)\n",
    "                    found_bbc_link = True\n",
    "                    break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        if not found_bbc_link:\n",
    "            print(f\"No BBC link found for '{name}' on {news_site}.\")\n",
    "            return\n",
    "\n",
    "        # Scrape data from the BBC article\n",
    "        time.sleep(random.uniform(2, 4))  # Reduced sleep time\n",
    "\n",
    "        try:\n",
    "            title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#main-content > article > div:nth-child(1) > h1'))).text\n",
    "        except TimeoutException:\n",
    "            title = 'NA'\n",
    "\n",
    "        try:\n",
    "            author = driver.find_element(By.CSS_SELECTOR, 'div[data-testid=\"byline-new\"] .sc-2b5e3b35-7').text\n",
    "        except NoSuchElementException:\n",
    "            author = 'NA'\n",
    "\n",
    "        try:\n",
    "            date = driver.find_element(By.CSS_SELECTOR, 'div.sc-2b5e3b35-1.jTEdni time').text\n",
    "        except NoSuchElementException:\n",
    "            date = 'NA'\n",
    "\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, 'div[data-component=\"text-block\"] p.sc-eb7bd5f6-0.fYAfXe')\n",
    "        text = ' '.join([para.text for para in paragraphs])\n",
    "\n",
    "        article_data.append({\n",
    "            'Name': name,\n",
    "            'Website': news_site,\n",
    "            'Link': driver.current_url,\n",
    "            'Title': title,\n",
    "            'Author': author,\n",
    "            'Date': date,\n",
    "            'Text': text\n",
    "        })\n",
    "\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "        print(f\"Error for '{name}' on {news_site}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Main function to process each name\n",
    "def process_names(names):\n",
    "    max_threads = min(5, len(names))  # Adjust thread count based on the number of names\n",
    "    with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(search_and_scrape, name, \"BBC\") for name in names]\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Collect exceptions if any\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the script\n",
    "process_names(names)\n",
    "\n",
    "# Create a DataFrame from the article data and save it to Excel\n",
    "if article_data:\n",
    "    df_articles = pd.DataFrame(article_data)\n",
    "    df_articles.to_excel('bbc_articles.xlsx', index=False)\n",
    "    print(\"Data saved to 'bbc_articles.xlsx'.\")\n",
    "else:\n",
    "    print(\"No articles scraped.\")\n",
    "\n",
    "print(\"Google search and scrape process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4a5d2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found BBC article for 'Apple': https://www.bbc.com/news/topics/crr7mlg0gqqt\n",
      "Found BBC article for 'Bitcoin': https://www.bbc.com/news/topics/c734j90em14t\n",
      "Found BBC article for 'Amazon': https://www.bbc.com/news/topics/c50znx8v8y4t\n",
      "Found BBC article for 'NVIDIA': https://www.bbc.com/news/topics/cewrlqz847yt\n",
      "[\n",
      "    {\n",
      "        \"Name\": \"Apple\",\n",
      "        \"Website\": \"BBC\",\n",
      "        \"Link\": \"https://www.bbc.com/news/topics/crr7mlg0gqqt\",\n",
      "        \"Title\": \"Apple\",\n",
      "        \"Author\": \"NA\",\n",
      "        \"Date\": \"NA\",\n",
      "        \"Text\": \"Google, Apple and TomTom say changes will be made to audio prompts after two women died. The EU ordered Apple to pay Ireland billions in unpaid taxes in September. It is the latest move from the tech giant to change how people search online using artificial intelligence. In July, Jack Chambers pledged €1.4bn in tax measures and new expenditure of €6.9bn It is the time of year when new handsets are unveiled, but they may offer only small improvements. Apple has been ordered to pay Ireland €14bn in unpaid taxes by Europe's top court. The European Court of Justice upheld a 2016 decision that said Apple received unlawful aid from Ireland. The firm says its new handset has been built for artificial intelligence as it looks to regain its edge. Shares in the company fall as much as 20%, contributing to a sharp fall in global stock markets.\"\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"NVIDIA\",\n",
      "        \"Website\": \"BBC\",\n",
      "        \"Link\": \"https://www.bbc.com/news/topics/cewrlqz847yt\",\n",
      "        \"Title\": \"Nvidia\",\n",
      "        \"Author\": \"NA\",\n",
      "        \"Date\": \"NA\",\n",
      "        \"Text\": \"The California-based technology giant has been one of the biggest beneficiaries of the AI boom. The two tech firms were among the first to see the commercial potential of AI. The artificial intelligence chip giant briefly took the top spot from the software company this week. Jensen Huang is at the forefront of an AI boom, which coincides with Nvidia's rise as a leading chip firm. Nvidia has been marked out as a winner from a wave of investments in artificial intelligence. The firm has benefited from the AI boom, making it the third-most valuable company in the US. Booming business at Nvidia sees investors bet the AI revolution will live up to its \\\"hype\\\". The artificial intelligence boom has helped Nvidia become one of the most valuable firms in the US. The firm's shares have soared since its earnings announcement last week and are now up more than 98%.\"\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"Amazon\",\n",
      "        \"Website\": \"BBC\",\n",
      "        \"Link\": \"https://www.bbc.com/news/topics/c50znx8v8y4t\",\n",
      "        \"Title\": \"Amazon\",\n",
      "        \"Author\": \"NA\",\n",
      "        \"Date\": \"NA\",\n",
      "        \"Text\": \"Watch the moment an Amazon lorry was filmed mounting the pavement in Ealing, crushing bollards. Amazon is ordering its staff back to the office five days a week, but the UK government is promoting flexible working. Michael Sheen stars alongside Ruth Wilson in the new drama depicting Prince Andrew's Newsnight interview. The Amazon series offered 1,000 participants the chance to win a cash prize of $5m. The e-commerce giant is ending hybrid working and will stop people hot-desking in the US. The star has made peace with continually being asked about the impact of having a famous actor for a dad. But she warns that Jeffrey Epstein's victims didn't get closure after the 2019 Newsnight interview. Bovingdon Airfield Studios is also where films such as 1917 and Deadpool & Wolverine were filmed. Roles in HR, IT and finance as well as warehouse packer positions available at Gateway 45 site.\"\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"Bitcoin\",\n",
      "        \"Website\": \"BBC\",\n",
      "        \"Link\": \"https://www.bbc.com/news/topics/c734j90em14t\",\n",
      "        \"Title\": \"Bitcoin\",\n",
      "        \"Author\": \"NA\",\n",
      "        \"Date\": \"NA\",\n",
      "        \"Text\": \"Why are still no closer to unmasking the mysterious Satoshi Nakamoto? How a group of Silicon Valley tech entrepreneurs plan to create \\\"the network state.\\\" Cryptocurrency has emerged as a key political battleground for Donald Trump and Republicans Jian Wen, 42, was involved in converting Bitcoin into assets including multi-million-pound houses. Peter McCormack says he has secured a 15-year lease on the club's Bedford ground. From Bitcoin 'halving' to ETFs, here's a look at some key crypto terms and what they mean. Peter McCormack says \\\"ambition is big\\\" and Real Bedford's attendances are increasing with promotions. Cameron and Tyler Winklevoss will become co-owners of Real Bedford. Jian Wen, 42, from north London, was involved in converting Bitcoin into assets like luxury houses.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode for better performance\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "def scrap_articles_bbc(names_list):\n",
    "    article_data = []\n",
    "\n",
    "    # Function to search, click the first link, scrape data, and close the browser\n",
    "    def search_and_scrape(name, news_site=\"BBC\"):\n",
    "        try:\n",
    "            service = Service(executable_path=msedgedriver_path)\n",
    "            driver = webdriver.Edge(service=service, options=options)\n",
    "            driver.set_page_load_timeout(15)  # Set a page load timeout\n",
    "            search_query = f\"{news_site} {name}\"\n",
    "            search_url = f\"https://www.google.com/search?q={search_query}\"\n",
    "\n",
    "            driver.get(search_url)\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "\n",
    "            # Locate the results and find \"bbc.com\" link\n",
    "            results = driver.find_elements(By.CSS_SELECTOR, \"div.g\")\n",
    "            found_bbc_link = False\n",
    "\n",
    "            for result in results:\n",
    "                try:\n",
    "                    cite_element = result.find_element(By.TAG_NAME, \"cite\")\n",
    "                    if \"bbc.com\" in cite_element.text:\n",
    "                        link = result.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                        print(f\"Found BBC article for '{name}': {link}\")\n",
    "                        driver.get(link)\n",
    "                        found_bbc_link = True\n",
    "                        break\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            if not found_bbc_link:\n",
    "                print(f\"No BBC link found for '{name}' on {news_site}.\")\n",
    "                return\n",
    "\n",
    "            # Wait for the content to load and scrape data from the BBC article\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "\n",
    "            try:\n",
    "                title = wait.until(EC.presence_of_element_located((By.TAG_NAME, 'h1'))).text\n",
    "            except TimeoutException:\n",
    "                title = 'NA'\n",
    "\n",
    "            try:\n",
    "                author = driver.find_element(By.CSS_SELECTOR, 'div[data-testid=\"byline\"]').text\n",
    "            except NoSuchElementException:\n",
    "                author = 'NA'\n",
    "\n",
    "            try:\n",
    "                date = driver.find_element(By.CSS_SELECTOR, 'time').get_attribute('datetime')\n",
    "            except NoSuchElementException:\n",
    "                date = 'NA'\n",
    "\n",
    "            paragraphs = driver.find_elements(By.CSS_SELECTOR, 'article p')\n",
    "            text = ' '.join([para.text for para in paragraphs if para.text])\n",
    "\n",
    "            article_data.append({\n",
    "                'Name': name,\n",
    "                'Website': news_site,\n",
    "                'Link': driver.current_url,\n",
    "                'Title': title,\n",
    "                'Author': author,\n",
    "                'Date': date,\n",
    "                'Text': text\n",
    "            })\n",
    "\n",
    "        except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "            print(f\"Error for '{name}' on {news_site}: {e}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    # Main function to process each name\n",
    "    def process_names(names):\n",
    "        max_threads = min(5, len(names))  # Adjust thread count based on the number of names\n",
    "        with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            futures = [executor.submit(search_and_scrape, name) for name in names]\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    future.result()  # Collect exceptions if any\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "\n",
    "    # Run the script\n",
    "    process_names(names_list)\n",
    "\n",
    "    # Return the collected article data in JSON format\n",
    "    return json.dumps(article_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "names = ['Apple', 'Amazon', 'NVIDIA', 'Bitcoin']\n",
    "result_json = scrap_articles_bbc(names)\n",
    "print(result_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "286a4cff",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 21 (413102873.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 24\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.read_excel('company_crypto_list.xlsx')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode for better performance\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "\n",
    "def scrap_articles_bbc(subject):\n",
    "\n",
    "# Load company and crypto names\n",
    "df = pd.read_excel('company_crypto_list.xlsx')\n",
    "names = df['Name'].dropna().tolist()\n",
    "\n",
    "# Initialize a list to store article data\n",
    "article_data = []\n",
    "\n",
    "# Function to search, click the first link, scrape data, and close the browser\n",
    "def search_and_scrape(name, news_site):\n",
    "    try:\n",
    "        service = Service(executable_path=msedgedriver_path)\n",
    "        driver = webdriver.Edge(service=service, options=options)\n",
    "        driver.set_page_load_timeout(15)  # Set a page load timeout\n",
    "        search_query = f\"{news_site} {name}\"\n",
    "        search_url = f\"https://www.google.com/search?q={search_query}\"\n",
    "\n",
    "        driver.get(search_url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Locate the results and find \"bbc.com\" link\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \"div.g\")\n",
    "        found_bbc_link = False\n",
    "\n",
    "        for result in results:\n",
    "            try:\n",
    "                cite_element = result.find_element(By.TAG_NAME, \"cite\")\n",
    "                if \"bbc.com\" in cite_element.text:\n",
    "                    link = result.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                    print(f\"Found BBC article for '{name}': {link}\")\n",
    "                    driver.get(link)\n",
    "                    found_bbc_link = True\n",
    "                    break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        if not found_bbc_link:\n",
    "            print(f\"No BBC link found for '{name}' on {news_site}.\")\n",
    "            return\n",
    "\n",
    "        # Scrape data from the BBC article\n",
    "        time.sleep(random.uniform(2, 4))  # Reduced sleep time\n",
    "\n",
    "        try:\n",
    "            title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#main-content > article > div:nth-child(1) > h1'))).text\n",
    "        except TimeoutException:\n",
    "            title = 'NA'\n",
    "\n",
    "        try:\n",
    "            author = driver.find_element(By.CSS_SELECTOR, 'div[data-testid=\"byline-new\"] .sc-2b5e3b35-7').text\n",
    "        except NoSuchElementException:\n",
    "            author = 'NA'\n",
    "\n",
    "        try:\n",
    "            date = driver.find_element(By.CSS_SELECTOR, 'div.sc-2b5e3b35-1.jTEdni time').text\n",
    "        except NoSuchElementException:\n",
    "            date = 'NA'\n",
    "\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, 'div[data-component=\"text-block\"] p.sc-eb7bd5f6-0.fYAfXe')\n",
    "        text = ' '.join([para.text for para in paragraphs])\n",
    "\n",
    "        article_data.append({\n",
    "            'Name': name,\n",
    "            'Website': news_site,\n",
    "            'Link': driver.current_url,\n",
    "            'Title': title,\n",
    "            'Author': author,\n",
    "            'Date': date,\n",
    "            'Text': text\n",
    "        })\n",
    "\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "        print(f\"Error for '{name}' on {news_site}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Main function to process each name\n",
    "def process_names(names):\n",
    "    max_threads = min(5, len(names))  # Adjust thread count based on the number of names\n",
    "    with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(search_and_scrape, name, \"BBC\") for name in names]\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Collect exceptions if any\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the script\n",
    "process_names(names)\n",
    "\n",
    "# Create a DataFrame from the article data and save it to Excel\n",
    "if article_data:\n",
    "    df_articles = pd.DataFrame(article_data)\n",
    "    df_articles.to_excel('bbc_articles.xlsx', index=False)\n",
    "    print(\"Data saved to 'bbc_articles.xlsx'.\")\n",
    "else:\n",
    "    print(\"No articles scraped.\")\n",
    "\n",
    "print(\"Google search and scrape process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6d001f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'django'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeoutException, NoSuchElementException, WebDriverException\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdjango\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonResponse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Path to Microsoft Edge WebDriver\u001b[39;00m\n\u001b[0;32m     14\u001b[0m msedgedriver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmouns\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfiverr\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOrders\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOrder 16\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mscrapping tool\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmsedgedriver.exe\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'django'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "from django.http import JsonResponse\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Function to search and scrape articles\n",
    "def search_and_scrape(name, news_site=\"BBC\"):\n",
    "    article_data = []\n",
    "    try:\n",
    "        service = Service(executable_path=msedgedriver_path)\n",
    "        driver = webdriver.Edge(service=service, options=options)\n",
    "        driver.set_page_load_timeout(15)\n",
    "        search_query = f\"{news_site} {name}\"\n",
    "        search_url = f\"https://www.google.com/search?q={search_query}\"\n",
    "\n",
    "        driver.get(search_url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Locate the results and find \"bbc.com\" link\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \"div.g\")\n",
    "        found_bbc_link = False\n",
    "\n",
    "        for result in results:\n",
    "            try:\n",
    "                cite_element = result.find_element(By.TAG_NAME, \"cite\")\n",
    "                if \"bbc.com\" in cite_element.text:\n",
    "                    link = result.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                    driver.get(link)\n",
    "                    found_bbc_link = True\n",
    "                    break\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "\n",
    "        if not found_bbc_link:\n",
    "            return {\"error\": f\"No BBC link found for '{name}' on {news_site}.\"}\n",
    "\n",
    "        # Scrape data from the BBC article\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        try:\n",
    "            title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#main-content > article > div:nth-child(1) > h1'))).text\n",
    "        except TimeoutException:\n",
    "            title = 'NA'\n",
    "\n",
    "        try:\n",
    "            author = driver.find_element(By.CSS_SELECTOR, 'div[data-testid=\"byline-new\"] .sc-2b5e3b35-7').text\n",
    "        except NoSuchElementException:\n",
    "            author = 'NA'\n",
    "\n",
    "        try:\n",
    "            date = driver.find_element(By.CSS_SELECTOR, 'div.sc-2b5e3b35-1.jTEdni time').text\n",
    "        except NoSuchElementException:\n",
    "            date = 'NA'\n",
    "\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, 'div[data-component=\"text-block\"] p.sc-eb7bd5f6-0.fYAfXe')\n",
    "        text = ' '.join([para.text for para in paragraphs])\n",
    "\n",
    "        article_data.append({\n",
    "            'Name': name,\n",
    "            'Website': news_site,\n",
    "            'Link': driver.current_url,\n",
    "            'Title': title,\n",
    "            'Author': author,\n",
    "            'Date': date,\n",
    "            'Text': text\n",
    "        })\n",
    "\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "        return {\"error\": f\"Error for '{name}' on {news_site}: {e}\"}\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return article_data\n",
    "\n",
    "# Django view function\n",
    "def scrape_articles_view(request):\n",
    "    if request.method == 'POST':\n",
    "        names = request.POST.getlist('names')\n",
    "        if not names:\n",
    "            return JsonResponse({\"error\": \"No names provided\"}, status=400)\n",
    "\n",
    "        max_threads = min(5, len(names))\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            futures = [executor.submit(search_and_scrape, name) for name in names]\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                if isinstance(result, list):\n",
    "                    results.extend(result)\n",
    "                else:\n",
    "                    results.append(result)\n",
    "\n",
    "        return JsonResponse(results, safe=False)\n",
    "    else:\n",
    "        return JsonResponse({\"error\": \"Invalid request method. Use POST.\"}, status=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f9b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found BBC article for 'Trump': https://www.bbc.com/news/topics/cp7r8vgl2lgt\n",
      "Found BBC article for 'Trump': https://www.bbc.com/news/live/czxrnw5qrprt\n",
      "Found BBC article for 'Trump': https://www.bbc.com/reel/video/p0k2snny/how-the-fall-of-the-berlin-wall-inspired-filmmakers\n",
      "hhhhh\n",
      "[{'Name': 'Trump', 'Website': 'BBC', 'Link': 'https://www.bbc.com/news/topics/cp7r8vgl2lgt', 'Title': '', 'Author': 'NA', 'Date': 'NA', 'Text': 'Republican Donald Trump, 78, is set to return to the White House after winning the 2024 presidential election against Kamala Harris. It marks a stunning political comeback for Trump four years after he lost the White House. Republican Donald Trump will be the next US president after securing a second term in the White House. Millions of Americans voted to give him a second chance - our North America editor Sarah Smith looks at why. Here\\'s what you need to know about the Trump family. Darren Jones says there \"shouldn\\'t be an element of conceding to illegal invasions from Russia\". Absentee voters living in the UK and Europe say their have ballots been challenged in bad faith. The Republican finishes the US presidential election with 312 electoral college votes, compared with Kamala Harris\\'s 226. The director of the emergency agency says a supervisor has been fired for \"reprehensible\" actions. Susie Wiles has been appointed chief of staff as the transition team vets other candidates for key roles. The powerful former speaker of the House suggested the Democrats could have fared better if the president stood down as candidate sooner. The Republican finishes the US presidential election with 312 electoral college votes, compared with Kamala Harris\\'s 226. Described by some as an \"enigma\", Mrs Trump is expected to return to her White House duties \"on her own terms\". The US government alleges Iran\\'s Revolutionary Guard tasked an Afghan national to devise a plan to kill Trump. The powerful Democrat says the party might have beaten Donald Trump if the president had \"gotten out sooner\". Both Trump fans and Harris supporters baselessly claimed large-scale voter fraud in Tuesday\\'s election. Inside Trump’s 2016 White House Darren Jones says there \"shouldn\\'t be an element of conceding to illegal invasions from Russia\". The Republican finishes the US presidential election with 312 electoral college votes, compared with Kamala Harris\\'s 226. The director of the emergency agency says a supervisor has been fired for \"reprehensible\" actions. Susie Wiles has been appointed chief of staff as the transition team vets other candidates for key roles. Described by some as an \"enigma\", Mrs Trump is expected to return to her White House duties \"on her own terms\". The US government alleges Iran\\'s Revolutionary Guard tasked an Afghan national to devise a plan to kill Trump. The powerful Democrat says the party might have beaten Donald Trump if the president had \"gotten out sooner\". Both Trump fans and Harris supporters baselessly claimed large-scale voter fraud in Tuesday\\'s election. The state is likely to be on the frontline of the president-elect\\'s immigration policies.'}, {'Name': 'Trump', 'Website': 'BBC', 'Link': 'https://www.bbc.com/news/live/czxrnw5qrprt', 'Title': 'Donald Trump wins 2024 US election in historic comeback', 'Author': 'NA', 'Date': 'NA', 'Text': 'Brandon Livesay\\nReporting from Washington DC Watch: Trump thanks America for electing him 47th president Assassination attempts, criminal convictions and a change in political opponent couldn’t stop Republican Donald Trump winning the 2024 US election. Trump swept to a decisive victory on Wednesday morning after winning several crucial battleground states. In three months’ time, the 45th president of the United States will become the 47th at an inauguration at the US Capitol. It’s the same location his supporters stormed and ransacked with a goal of stopping the certification of Joe Biden’s election on 6 January 2021. Since then, Trump has made a remarkable political comeback that culminated with a victory speech to a sea of supporters wearing his iconic red MAGA caps. \"America has given us an unprecedented and powerful mandate,” he said to a crowd heaving with excitement. At the same time, hope had drained away from Kamala Harris\\'s supporters, who were leaving in droves from the Democratic Party event where she was hoping to make her own victory speech. Instead, she gave a concession speech telling tearful supporters to \"never give up\" on their ideals and pledging a peaceful transfer of power. America has chosen its next leader. Dulcie Lee\\nLive editor, reporting from Washington DC Watch: How the night unfolded in three minutes After a truly momentous 48 hours, there\\'s undoubtedly a lot to digest. Fortunately, whether you want a speedy overview or a deep dive, we\\'ve got you covered. The top analysis: What\\'s next: Get new perspectives: Stay up to date: For ongoing updates, read our latest live coverage. For a quick overview, read our story of the night, or watch the highlights in 14 minutes on BBC iPlayer. And for the blow-by-blow account of an extraordinary night, just keep scrolling. Away from the presidential race, Republicans have also retaken control of the US Senate, after flipping seats in West Virginia, Ohio and Montana. Several races for seats in the House of Representatives remain undecided, but its control is also currently leaning Republican, according to our US partner CBS News. If successful, that would put the party in control of Congress, the Senate and the White House when Trump is sworn in in January. All in, a clean sweep for the Republicans is looking likely after a hotly-contested campaign. Votes in Arizona and Nevada are still being counted - but we already have more than enough results to determine several key outcomes Twenty-four hours ago, it grew increasingly clear that Donald Trump was on track to win the presidency of the United States, and gain an historic second term. The hours and events that followed have been eventful, to say the least. Here\\'s a look back on the day, in pictures: Trump won the presidential election in what our North America editor Sarah Smith dubbed \"the most dramatic comeback in US political history\". Trump\\'s supporters were elated at the news, with Trump sweeping a definitive majority of electoral college votes The president-elect was joined by his family on stage as he delivered his victory speech from a watch party in Florida Hours later, Kamala Harris gave her concession speech at her alma mater, Howard University, in Washington. In an emotional address, she urged her supporters not to give up fighting for a brighter future for America The vice-president was joined by hundreds of her supporters and political allies, who helped her shape her election campaign in around 100 days Harris\\'s running mate, Governor Tim Walz, watched the vice-president deliver her speech alongside his wife, Gwen Walz Former and now incoming First Lady Melania Trump has shared a statement following Donald Trump\\'s second presidential election victory. Posting on X she writes: \"The majority of Americans have entrusted us with this important responsibility. We will safeguard the heart of our republic – freedom. \"I anticipate the citizens of our nation re-joining in commitment to each other and rising above ideology for the sake of individual liberty, economic prosperity, and security. \"American energy, skill, and initiative will bring together our best minds to propel our nation forward forevermore.\" Former President Bill Clinton and ex-Secretary of State Hillary Clinton - who was defeated by Donald Trump in 2016 - have released a joint statement reacting to the election result. It reads: \"The American people have voted, and Donald Trump and JD Vance will be the next president and vice president of the United States. \"We wish them well and hope they will govern for all of us.\" Donald Trump\\'s former ambassador to Nato says she hopes he will \"let Ukraine attack [Russian] forces on the other side of the border\" to end the stalemate in the war. Speaking to the BBC, Kay Bailey Hutchinson says the government in Kyiv should aim to \"get an agreement that would be negotiated in their favour\" after talks with a new Trump White House. Trump has previously criticised the amount of of aid spending the US has committed to Ukraine under Joe Biden, and is widely seen as being less supportive of Kyiv\\'s war effort. Hutchinson also says Trump will seek to ensure \"free and fair trade\" with China, or move manufacturing back to the US to create jobs at home. Courtney Subramanian\\nReporting from the convention Nearly a month ago, Kamala Harris appeared on ABC\\'s The View in what was expected to be a friendly interview aimed at pitching herself to Americans who wanted to know more about her. The sit-down was quickly overshadowed by her response to a question on what she would have done differently to Joe Biden. \"Not a thing comes to mind,\" she replied. Harris\\'s answer - which became a Republican attack ad on loop - underscored the political headwinds that her jumpstart campaign failed to overcome in her decisive loss to Donald Trump on Tuesday. Publicly, she conceded the race late on Wednesday afternoon, telling supporters \"do not despair\" - but soul-searching over where she went wrong and what else she could have done will likely take longer, as Democrats begin finger-pointing and raising questions about the future of the party. You can read more analysis about Harris\\'s collapse here. Control of the House of Representatives is currently leaning Republican, according to our US partner CBS News. As of right now, Republicans are projected to win 211 seats - leaving them just seven short of controlling the House. The Democrats would need 15 more seats to clinch a majority. Some context: Republicans have already retaken control of the US Senate. If the same were to happen in the House, that would put the party in control of Congress, the Senate and the White House when President-Elect Donald Trump is sworn in in January. Peter Hoskins\\nBusiness reporter, BBC News Singapore Most stock markets in Asia lost ground on Thursday as investors consider the impact of a second term as president for Donald Trump on the region and the global economy as a whole. On the campaign trail he pledged to raise trade tariffs on imports to the US, especially on goods from China. Australia’s ASX 200 index and the Nikkei 225 in Japan were down by about 0.3% in morning trading after rising sharply on Wednesday. The Hang Seng in Hong Kong and the Shanghai Composite in Mainland China were both up by more than half a percent. The US dollar edged up after jumping by about 1.65% against a basket of other major currencies as Trump moved closer to victory. Earlier, major stock markets in the US hit record highs on expectations that the president-elect’s plans to cut taxes and raise tariffs will push up inflation and reduce the pace of interest rate cuts. Higher rates for longer mean investors will get better returns on savings and investments they hold in dollars. Natalie Sherman\\nNew York business reporter This graphic shows some of the advisers who were on stage with Donald Trump at his victory speech. As Donald Trump emerges victorious, eyes will now turn to his takeover of the White House. Howard Lutnick, one of the people leading the transition team, was on stage with Trump last night. The billionaire chief executive of the financial firm Cantor Fitzgerald has already been soliciting resumes as he looks to fill thousands of political roles for the new administration. Lutnick has grisly experience of rapidly staffing up. The 11 September attacks on the World Trade Center killed every Cantor Fitzgerald employee in the office that day – more than 650 people, including Lutnick\\'s brother. Despite his Wall Street ties, Lutnick has said he is committed to Trump’s populist Make America Great Again agenda. “His transition team will ensure the implementation of President Trump’s common sense agenda starting on Day 1,” Lutnick and co-chair Linda McMahon said in a statement on Wednesday. President-Elect Donald Trump will begin choosing his cabinet in the \"days and weeks ahead\", the team leading his transition to the White House says. In a statement, co-chairs Linda McMahon and Howard Lutnick say they will presenting Trump with a \"wide array of experts from which he can select for his team\". They say he will select personnel that enact policies that \"make the life of Americans affordable, safe, and secure\". While the ultimate result may be a foregone conclusion, we\\'re still waiting to see the final results from some states. Our next complete set of results will probably be coming in from Nevada, one of the key swing states, where 90% of votes have been counted so far. The state is home to more than three million people and is famous for Las Vegas and the Hoover Dam. Of the votes counted so far, about 51.6% have gone to Donald Trump, with 46.7% going to Kamala Harris. Well, Kamala Harris will continue to serve the rest of her term as vice-president alongside President Joe Biden, until the handover of power to Donald Trump and JD Vance on 20 January. But after President-Elect Trump and Vice-President-Elect JD Vance are sworn into office on inauguration day, both Biden and Harris will no longer have any political position in the US government. And unlike in UK politics, there is no equivalent position of \"leader of the opposition\" - Harris will just be out of a job. Not that she\\'ll be short of offers. Trump and Modi developed a friendship during the president-elect\\'s first term in office Leaders from around the world have been reacting to Donald Trump\\'s election victory. Here\\'s what some had to say: India\\'s Prime Minister Narendra Modi offered his \"heartiest congratulations\" to his \"friend\" and said they would work together to \"promote global peace, stability and prosperity\". Brazilian President Lula Da Silva said he hopes Trump \"cares about working for the world to have peace\" and that his relationship with Brazil \"will be civilised\". Ukrainian President Volodymyr Zelensky - whose relations with Trump will be closely watched in the coming months - said the pair held an \"excellent\" call after this victory. UK Prime Minister Sir Keir Starmer offered \"hearty congratulations\" and said he looked forward to working with him \"across all areas of the special relationship\". Earlier today, Vice-President Kamala Harris gave an emotional concession speech on the steps of her alma mater, Howard University, in Washington. She urged the crowd watching not to give up fighting for a brighter future for America - a message she has reiterated to her supporters over her campaign email. In it, Harris is emphatic in her gratitude for those who backed her. She acknowledges that the outcome of the election \"is not what we wanted\" but adds: \"The light of America\\'s promise will always burn bright - as long as we never give up and keep fighting\". \"While I concede this election, I do not concede the fight that fuelled this campaign,\" she says. This is not the time to throw up our hands. This is a time to roll up our sleeves.\" Kamala Harris Lily Jamali\\nSan Francisco correspondent Elon Musk had campaigned in support of Donald Trump\\'s presidency Donald Trump’s return to the White House might prove to be a win for one of his most visible supporters: Elon Musk. The world\\'s richest man spent election night in Florida with Trump at his Mar-a-Lago resort as returns came in. \"The people of America gave Donald Trump a crystal clear mandate for change tonight,\" Musk wrote on X - the platform he owns - as Trump’s victory began to appear all but certain. And at his victory speech at the Palm Beach Convention Centre, Trump spent several minutes praising Musk and recounting the successful landing of a rocket manufactured by one of Musk\\'s companies, SpaceX. You can read more on what a Trump presidency might mean for Musk here. Senate Majority Leader Chuck Schumer, a Democrat from New York, writes on X that Senate Democrats will be committed to working with Republican colleagues after the party won the majority in the upper chamber. \"As I\\'ve said time and again, in both the majority and the minority, the only way to get things done in the Senate is through bipartisan legislation while maintaining our principles - and the next two years will be no different.\" he adds. The Republican Party retook control of the Senate, after flipping seats in West Virginia, Ohio and Montana. A handful of races remain undecided, with ballots still being counted. Here\\'s a look at where things stand: George Bowden\\nBBC News President-elect Donald Trump will be sworn in at the presidential inauguration on 20 January 2025. It is at this point he will legally assume the power and responsibilities of the presidency. Prior to January, the electoral college process plays out. Each state generally awards their electoral college votes to whoever wins the popular vote. This is confirmed on 17 December. The new US Congress then meets on 6 Januaryto count the electoral college votes and certify the results, thus officially confirming the next president. It was this part of the process that Trump\\'s supporters tried to stop when they stormed the US Capitol in 2021 after he refused to concede defeat to Joe Biden. Rachel Looker\\nReporting from Washington, DC Recent polling data shows white men represented overwhelmingly the biggest percentage of voters who backed president-elect Trump in the 2024 presidential election, at 60%. Close behind were Latino men, who supported the former president by 19 more points than in the 2020 vote. Trump received 55% of the votes from Latino men, while Harris won 43%, marking the greatest demographic shift this election cycle. Latino women also increased in their support for Trump, with 38% backing the president-elect. This is an eight-point increase compared to 2020.'}, {'Name': 'Trump', 'Website': 'BBC', 'Link': 'https://www.bbc.com/reel/video/p0k2snny/how-the-fall-of-the-berlin-wall-inspired-filmmakers', 'Title': 'How the fall of the Berlin Wall inspired filmmakers', 'Author': 'NA', 'Date': 'NA', 'Text': ''}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "options = webdriver.EdgeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode for better performance\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "def search_and_scrape(name, news_site=\"BBC\"):\n",
    "    article_data = []\n",
    "    try:\n",
    "        service = Service(executable_path=msedgedriver_path)\n",
    "        driver = webdriver.Edge(service=service, options=options)\n",
    "        driver.set_page_load_timeout(15)\n",
    "        search_query = f\"{news_site} {name}\"\n",
    "        search_url = f\"https://www.google.com/search?q={search_query}\"\n",
    "\n",
    "        driver.get(search_url)\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "\n",
    "        # Collect articles across multiple pages\n",
    "        bbc_links = []\n",
    "\n",
    "        while len(bbc_links) < 3:  # Stop after collecting at least 3 articles\n",
    "            results = driver.find_elements(By.CSS_SELECTOR, \"div.g\")\n",
    "            for result in results:\n",
    "                try:\n",
    "                    cite_element = result.find_element(By.TAG_NAME, \"cite\")\n",
    "                    if \"bbc.com\" in cite_element.text:\n",
    "                        link = result.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                        if link not in bbc_links:\n",
    "                            bbc_links.append(link)\n",
    "                            print(f\"Found BBC article for '{name}': {link}\")\n",
    "                            if len(bbc_links) >= 3:\n",
    "                                break\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            # Check if there are more pages and click \"Next\" if available\n",
    "            try:\n",
    "                next_button = driver.find_element(By.ID, \"pnnext\")\n",
    "                next_button.click()\n",
    "                time.sleep(random.uniform(2, 4))  # Random delay for loading the next page\n",
    "            except NoSuchElementException:\n",
    "                print(\"No more pages available.\")\n",
    "                break\n",
    "\n",
    "        if not bbc_links:\n",
    "            return {\"error\": f\"No BBC link found for '{name}' on {news_site}.\"}\n",
    "\n",
    "        # Iterate through the collected links and scrape them\n",
    "        for link in bbc_links[:3]:  # Scrape only the first 3 unique links collected\n",
    "            driver.get(link)\n",
    "            time.sleep(random.uniform(2, 4))  # Random delay for page load\n",
    "\n",
    "            # Extract title\n",
    "            try:\n",
    "                title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h1'))).text\n",
    "            except TimeoutException:\n",
    "                title = 'NA'\n",
    "\n",
    "            # Extract author (try multiple selectors)\n",
    "            try:\n",
    "                author = driver.find_element(By.CSS_SELECTOR, 'div[data-testid*=\"byline\"]').text\n",
    "            except NoSuchElementException:\n",
    "                try:\n",
    "                    author = driver.find_element(By.CSS_SELECTOR, '.byline__name').text  # Alternative selector\n",
    "                except NoSuchElementException:\n",
    "                    author = 'NA'\n",
    "\n",
    "            # Extract date (try multiple selectors)\n",
    "            try:\n",
    "                date = driver.find_element(By.CSS_SELECTOR, 'time').text\n",
    "            except NoSuchElementException:\n",
    "                try:\n",
    "                    date = driver.find_element(By.CSS_SELECTOR, 'span.date').text  # Alternative selector\n",
    "                except NoSuchElementException:\n",
    "                    date = 'NA'\n",
    "\n",
    "            # Extract text\n",
    "            paragraphs = driver.find_elements(By.CSS_SELECTOR, 'article p')\n",
    "            text = ' '.join([para.text for para in paragraphs])\n",
    "\n",
    "            article_data.append({\n",
    "                'Name': name,\n",
    "                'Website': news_site,\n",
    "                'Link': driver.current_url,\n",
    "                'Title': title,\n",
    "                'Author': author,\n",
    "                'Date': date,\n",
    "                'Text': text\n",
    "            })\n",
    "\n",
    "    except (TimeoutException, NoSuchElementException, WebDriverException) as e:\n",
    "        print(f\"Error for '{name}' on {news_site}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return article_data\n",
    "\n",
    "\n",
    "result = search_and_scrape(\"Trump\")\n",
    "print(\"hhhhh\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Tesla', 'Website': 'BBC', 'Link': 'https://www.bbc.com/news/topics/c8nq32jwjnmt', 'Title': 'NA', 'Author': 'NA', 'Date': 'NA', 'Text': ''}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b2fd-4dfe-4812-9b1b-5da35eaf3e45",
   "metadata": {},
   "source": [
    "#### NCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595fb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search for 'Tesla' on CNN\n",
      "No CNN links found for 'Tesla'. Exiting search.\n",
      "Final save: 0 articles saved to 'cnn_articles.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4508c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search for 'Tesla' on CNN\n",
      "Loading article page: https://www.cnn.com/markets/stocks/TSLA\n",
      "Article title: Tesla, Inc.\n",
      "Loading article page: https://www.cnn.com/2024/10/23/business/tesla-earnings/index.html\n",
      "Article title: Tesla cuts its costs to build cars, boosting earnings\n",
      "Loading article page: https://www.cnn.com/2024/10/18/business/tesla-fsd-federal-investigation/index.html\n",
      "Article title: Feds investigating safety of Tesla’s ‘Full Self-Driving’ feature\n",
      "Loading article page: https://www.cnn.com/2024/10/10/business/elon-musk-tesla-robotaxi-event/index.html\n",
      "Article title: Elon Musk is promising to unveil the future of Tesla tonight\n",
      "Loading article page: https://www.cnn.com/2024/10/10/business/elon-musk-tesla-robotaxis/index.html\n",
      "Article title: Elon Musk unveils his ‘Cybercab’ robotaxi\n",
      "Loading article page: https://www.cnn.com/2024/10/02/business/tesla-sales/index.html\n",
      "Article title: Tesla posts first sales gain of the year but shares fall as competition heats up\n",
      "Loading article page: https://www.cnn.com/2024/07/05/business/tesla-enters-chinese-government-purchase-list-for-first-time-intl-hnk/index.html\n",
      "Article title: Tesla is now an official Chinese government car\n",
      "Loading article page: https://www.cnn.com/2024/10/03/business/tesla-cybertruck-recall-october-2024/index.html\n",
      "Article title: Tesla recalls 27,000 Cybertrucks due to a rearview camera issue\n",
      "Final save: 8 articles saved to 'cnn_articles.xlsx'.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd95102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search for 'Tesla' on CNN\n",
      "Loading article page: https://www.cnn.com/markets/stocks/TSLA\n",
      "Article title: Tesla, Inc.\n",
      "Loading article page: https://www.cnn.com/2024/10/23/business/tesla-earnings/index.html\n",
      "Article title: Tesla cuts its costs to build cars, boosting earnings\n",
      "Loading article page: https://www.cnn.com/2024/11/06/business/video/musk-net-worth-tesla-trump-digvid\n",
      "Article title: \n",
      "Loading article page: https://www.cnn.com/2024/10/18/business/tesla-fsd-federal-investigation/index.html\n",
      "Article title: Feds investigating safety of Tesla’s ‘Full Self-Driving’ feature\n",
      "Loading article page: https://www.cnn.com/2024/10/10/business/elon-musk-tesla-robotaxi-event/index.html\n",
      "Article title: Elon Musk is promising to unveil the future of Tesla tonight\n",
      "Loading article page: https://www.cnn.com/2024/10/10/business/elon-musk-tesla-robotaxis/index.html\n",
      "Article title: Elon Musk unveils his ‘Cybercab’ robotaxi\n",
      "Loading article page: https://www.cnn.com/2024/10/02/business/tesla-sales/index.html\n",
      "Article title: Tesla posts first sales gain of the year but shares fall as competition heats up\n",
      "Loading article page: https://www.cnn.com/2024/07/05/business/tesla-enters-chinese-government-purchase-list-for-first-time-intl-hnk/index.html\n",
      "Article title: Tesla is now an official Chinese government car\n",
      "Loading article page: https://www.cnn.com/2024/10/03/business/tesla-cybertruck-recall-october-2024/index.html\n",
      "Article title: Tesla recalls 27,000 Cybertrucks due to a rearview camera issue\n",
      "Final save: 9 articles saved to 'cnn_articles.xlsx'.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2b1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search for 'Tesla' on CNN\n",
      "Loading article page: https://www.cnn.com/markets/stocks/TSLA\n",
      "Article title: Tesla, Inc.\n",
      "Skipped saving article from 'https://www.cnn.com/markets/stocks/TSLA' because text is empty.\n",
      "Loading article page: https://www.cnn.com/2024/10/23/business/tesla-earnings/index.html\n",
      "Article title: Tesla cuts its costs to build cars, boosting earnings\n",
      "Loading article page: https://www.cnn.com/2024/11/06/business/video/musk-net-worth-tesla-trump-digvid\n",
      "Article title: \n",
      "Skipped saving article from 'https://www.cnn.com/2024/11/06/business/video/musk-net-worth-tesla-trump-digvid' because text is empty.\n",
      "Loading article page: https://www.cnn.com/2024/10/18/business/tesla-fsd-federal-investigation/index.html\n",
      "Article title: Feds investigating safety of Tesla’s ‘Full Self-Driving’ feature\n",
      "Loading article page: https://www.cnn.com/2024/10/10/business/elon-musk-tesla-robotaxi-event/index.html\n",
      "Article title: Elon Musk is promising to unveil the future of Tesla tonight\n",
      "Loading article page: https://www.cnn.com/2024/10/10/business/elon-musk-tesla-robotaxis/index.html\n",
      "Article title: Elon Musk unveils his ‘Cybercab’ robotaxi\n",
      "Loading article page: https://www.cnn.com/2024/10/02/business/tesla-sales/index.html\n",
      "Article title: Tesla posts first sales gain of the year but shares fall as competition heats up\n",
      "Loading article page: https://www.cnn.com/2024/07/05/business/tesla-enters-chinese-government-purchase-list-for-first-time-intl-hnk/index.html\n",
      "Article title: Tesla is now an official Chinese government car\n",
      "Loading article page: https://www.cnn.com/2024/10/03/business/tesla-cybertruck-recall-october-2024/index.html\n",
      "Article title: Tesla recalls 27,000 Cybertrucks due to a rearview camera issue\n",
      "Final save: 7 articles saved to 'cnn_articles.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "# Path to Microsoft Edge WebDriver\n",
    "msedgedriver_path = r'C:\\\\Users\\\\mouns\\\\Documents\\\\fiverr\\\\Orders\\\\Order 16\\\\scrapping tool\\\\msedgedriver.exe'\n",
    "\n",
    "# List of user agents to randomly choose from\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:86.0) Gecko/20100101 Firefox/86.0\",\n",
    "    \"Mozilla/5.0 (Linux; Android 10; Pixel 3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.93 Mobile Safari/537.36\"\n",
    "]\n",
    "\n",
    "# Load company names\n",
    "df = pd.read_excel('company_crypto_list.xlsx')  # Your input file with company/crypto names\n",
    "names = df['Name'].dropna().tolist()  # Get the list of names\n",
    "\n",
    "# Initialize a list to store article data\n",
    "article_data = []\n",
    "\n",
    "# Function to save data to Excel\n",
    "def save_to_excel(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(filename, index=False)\n",
    "\n",
    "# Function to perform a random search to mimic human activity\n",
    "def perform_random_search(driver):\n",
    "    random_query = f\"random search {random.randint(1000, 9999)}\"\n",
    "    search_url = f\"https://www.google.com/search?q={random_query}\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(random.uniform(2, 4))  # Short delay to simulate browsing\n",
    "\n",
    "# Function to search for CNN links and scrape data\n",
    "def search_and_scrape(name):\n",
    "    service = Service(executable_path=msedgedriver_path)\n",
    "\n",
    "    def initialize_driver():\n",
    "        options = Options()\n",
    "        options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "        return webdriver.Edge(service=service, options=options)\n",
    "    \n",
    "    driver = initialize_driver()\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    \n",
    "    search_query = f\"{name} site:cnn.com\"\n",
    "    search_url = f\"https://www.google.com/search?q={search_query}\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Starting search for '{name}' on CNN\")\n",
    "        driver.get(search_url)\n",
    "        \n",
    "        # Random delay to avoid detection\n",
    "        time.sleep(random.uniform(8, 12))\n",
    "        \n",
    "        # Locate and retrieve CNN links from search results\n",
    "        cnn_links = []\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, 'div.g')\n",
    "        for result in results:\n",
    "            try:\n",
    "                cite_element = result.find_element(By.TAG_NAME, 'cite')\n",
    "                if \"cnn.com\" in cite_element.text:\n",
    "                    link = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    if link not in cnn_links:\n",
    "                        cnn_links.append(link)\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "        \n",
    "        if not cnn_links:\n",
    "            print(f\"No CNN links found for '{name}'. Exiting search.\")\n",
    "            return\n",
    "        \n",
    "        for link in cnn_links:\n",
    "            # Perform a random search to avoid detection\n",
    "            perform_random_search(driver)\n",
    "            \n",
    "            # Go to the CNN article link\n",
    "            driver.get(link)\n",
    "            time.sleep(random.uniform(8, 12))  # Random delay\n",
    "            \n",
    "            print(f\"Loading article page: {link}\")\n",
    "            \n",
    "            try:\n",
    "                # Extract article title\n",
    "                title_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'h1')))\n",
    "                article_title = title_element.text\n",
    "                print(f\"Article title: {article_title}\")\n",
    "                \n",
    "                # Use the current date as the article date\n",
    "                current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "                \n",
    "                # Extract Article Text\n",
    "                try:\n",
    "                    # Target paragraphs within the main article content container\n",
    "                    text_elements = driver.find_elements(By.CSS_SELECTOR, 'div.article__content p.paragraph')\n",
    "                    article_text = ' '.join([element.text for element in text_elements if element.text])\n",
    "                except NoSuchElementException:\n",
    "                    article_text = 'NA'\n",
    "                \n",
    "                # Store article data\n",
    "                if article_text.strip():  # Ensures text is not just whitespace\n",
    "                    article_data.append({\n",
    "                        'Name': name,\n",
    "                        'Article Title': article_title,\n",
    "                        'Date': current_date,\n",
    "                        'Text': article_text,\n",
    "                        'Link': link\n",
    "                    })\n",
    "\n",
    "                    # Save to Excel after every 10 articles\n",
    "                    if len(article_data) % 10 == 0:\n",
    "                        save_to_excel(article_data, 'cnn_articles.xlsx')\n",
    "                        print(f\"Saved {len(article_data)} articles to 'cnn_articles.xlsx'.\")\n",
    "                else:\n",
    "                    print(f\"Skipped saving article from '{link}' because text is empty.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting details from '{link}': {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing '{name}': {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Using ThreadPoolExecutor to process multiple names concurrently\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = {executor.submit(search_and_scrape, name): name for name in names}\n",
    "    for future in as_completed(futures):\n",
    "        name = futures[future]\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{name}': {e}\")\n",
    "\n",
    "# Final save to ensure any remaining articles are saved\n",
    "save_to_excel(article_data, 'cnn_articles.xlsx')\n",
    "print(f\"Final save: {len(article_data)} articles saved to 'cnn_articles.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06619424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
