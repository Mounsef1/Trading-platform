{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\mouns\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mouns\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: r/TeslaMotors is the subreddit you're looking for\n",
      "URL: https://www.reddit.com/r/teslamotors\n",
      "Score: 47\n",
      "Comments: 11\n",
      "----------------------------------------\n",
      "Title: Sad day. Tesla's Lab on Long Island Burned to the ground.\n",
      "URL: https://v.redd.it/cu7wpqk8ss1c1\n",
      "Score: 210\n",
      "Comments: 63\n",
      "----------------------------------------\n",
      "Title: Tesla's FBI File and US Patents\n",
      "URL: https://www.reddit.com/r/Tesla/comments/17o6ku7/teslas_fbi_file_and_us_patents/\n",
      "Score: 38\n",
      "Comments: 11\n",
      "----------------------------------------\n",
      "Title: Tubular linear motor mail transport 1886 Port Electric Co electro-port\n",
      "URL: https://i.redd.it/pgopjnlnkgxb1.png\n",
      "Score: 81\n",
      "Comments: 5\n",
      "----------------------------------------\n",
      "Title: Solar power utility in Ralph 124C 41+ (1911)\n",
      "URL: https://i.redd.it/oowyluj0o2qb1.png\n",
      "Score: 79\n",
      "Comments: 7\n",
      "----------------------------------------\n",
      "Title: Integzaâ€™s Building Nikola Tesla's Bladeless Turbine With TesTur Energy!\n",
      "URL: https://youtu.be/Tuzh9mHvzkk\n",
      "Score: 31\n",
      "Comments: 10\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Reddit API credentials (replace these with your actual values)\n",
    "client_id = '27QbrBstNI0qx3ACSCOsAw'\n",
    "client_secret = 'L1gYXRJ3CQ0dfrXQTfoYxELkiksQdQ'\n",
    "user_agent = 'trading_co_crawler'  # Can be any descriptive name\n",
    "\n",
    "# Initialize PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Function to fetch posts\n",
    "def fetch_posts(subreddit_name, limit=10):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    for post in subreddit.hot(limit=limit):  # Fetch 'hot' posts\n",
    "        posts.append({\n",
    "            'title': post.title,\n",
    "            'url': post.url,\n",
    "            'score': post.score,\n",
    "            'comments': post.num_comments,\n",
    "            'created_utc': post.created_utc\n",
    "        })\n",
    "\n",
    "    return posts\n",
    "\n",
    "# Example usage\n",
    "subreddit_name = 'Tesla'  # Replace with your desired subreddit\n",
    "posts = fetch_posts(subreddit_name, limit=20)\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"Title: {post['title']}\")\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Score: {post['score']}\")\n",
    "    print(f\"Comments: {post['comments']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: r/TeslaMotors is the subreddit you're looking for\n",
      "URL: https://www.reddit.com/r/teslamotors\n",
      "Score: 45\n",
      "Comments: 11\n",
      "Text: ...\n",
      "----------------------------------------\n",
      "Title: Sad day. Tesla's Lab on Long Island Burned to the ground.\n",
      "URL: https://v.redd.it/cu7wpqk8ss1c1\n",
      "Score: 210\n",
      "Comments: 63\n",
      "Text: ...\n",
      "----------------------------------------\n",
      "Title: Tesla's FBI File and US Patents\n",
      "URL: https://www.reddit.com/r/Tesla/comments/17o6ku7/teslas_fbi_file_and_us_patents/\n",
      "Score: 38\n",
      "Comments: 11\n",
      "Text: FBI File on Tesla (Declassified):\n",
      "\n",
      "http://libgen.is/book/index.php?md5=D4229DB677A6FB2137B5CBB78C16653A\n",
      "\n",
      "Tesla's Lectures, Patents, and Articles:\n",
      "\n",
      "http://libgen.is/book/index.php?md5=35F015A835D589FE5...\n",
      "----------------------------------------\n",
      "Title: Tubular linear motor mail transport 1886 Port Electric Co electro-port\n",
      "URL: https://i.redd.it/pgopjnlnkgxb1.png\n",
      "Score: 82\n",
      "Comments: 5\n",
      "Text: ...\n",
      "----------------------------------------\n",
      "Title: Solar power utility in Ralph 124C 41+ (1911)\n",
      "URL: https://i.redd.it/oowyluj0o2qb1.png\n",
      "Score: 81\n",
      "Comments: 7\n",
      "Text: ...\n",
      "----------------------------------------\n",
      "Title: Integzaâ€™s Building Nikola Tesla's Bladeless Turbine With TesTur Energy!\n",
      "URL: https://youtu.be/Tuzh9mHvzkk\n",
      "Score: 31\n",
      "Comments: 10\n",
      "Text: ...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Reddit API credentials (replace these with your actual values)\n",
    "client_id = '27QbrBstNI0qx3ACSCOsAw'\n",
    "client_secret = 'L1gYXRJ3CQ0dfrXQTfoYxELkiksQdQ'\n",
    "user_agent = 'trading_co_crawler'  # Can be any descriptive name\n",
    "\n",
    "# Initialize PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Function to fetch posts\n",
    "def fetch_posts(subreddit_name, limit=10):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    for post in subreddit.hot(limit=limit):  # Fetch 'hot' posts\n",
    "        posts.append({\n",
    "            'title': post.title,\n",
    "            'url': post.url,\n",
    "            'score': post.score,\n",
    "            'comments': post.num_comments,\n",
    "            'created_utc': post.created_utc,\n",
    "            'text': post.selftext  # Add the post text here\n",
    "        })\n",
    "\n",
    "    return posts\n",
    "\n",
    "# Example usage\n",
    "subreddit_name = 'Tesla'  # Replace with your desired subreddit\n",
    "posts = fetch_posts(subreddit_name, limit=20)\n",
    "\n",
    "for post in posts:\n",
    "    print(f\"Title: {post['title']}\")\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Score: {post['score']}\")\n",
    "    print(f\"Comments: {post['comments']}\")\n",
    "    print(f\"Text: {post['text'][:200]}...\")  # Display the first 200 characters of the text\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fetching Recent Posts ---\n",
      "Fetching posts from TeslaMotors since 2024-11-22T23:58:06.718652+00:00\n",
      "Title: Curious. Wondering what passenger side mirror camera like setup is. \n",
      "URL: https://i.redd.it/8845w30ikw2e1.jpeg\n",
      "Score: 60\n",
      "Comments: 32\n",
      "Created at (UTC): 2024-11-24 19:41:43+00:00\n",
      "Text: Saw this mounted on a Tesla model 3 on the streets of SF. ...\n",
      "----------------------------------------\n",
      "Title: FSD 13 is coming soon, Musk\n",
      "URL: https://www.teslaoracle.com/2024/11/24/fsd-v13-is-coming-soon-says-tesla-ceo-elon-musk/\n",
      "Score: 0\n",
      "Comments: 24\n",
      "Created at (UTC): 2024-11-24 16:11:28+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Tesla and Rivian have reached a â€˜conditionalâ€™ settlement in lawsuit over trade secrets | Tesla accused Rivian of poaching its employees in a 2020 lawsuit.\n",
      "URL: https://www.engadget.com/transportation/evs/tesla-and-rivian-have-reached-a-conditional-settlement-in-lawsuit-over-trade-secrets-214721559.html\n",
      "Score: 240\n",
      "Comments: 20\n",
      "Created at (UTC): 2024-11-23 22:01:40+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Saw the CyberCab In Person In Miami Showroom. \n",
      "URL: https://www.reddit.com/gallery/1gy7kem\n",
      "Score: 387\n",
      "Comments: 148\n",
      "Created at (UTC): 2024-11-23 19:24:08+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Buc-eeâ€™s in Smiths Grove chargers are online\n",
      "URL: https://i.redd.it/9ln8wm9yxk2e1.jpeg\n",
      "Score: 132\n",
      "Comments: 9\n",
      "Created at (UTC): 2024-11-23 04:35:44+00:00\n",
      "Text: After having the chargers sitting there for almost two months, they finally came online today....\n",
      "----------------------------------------\n",
      "Title: Improving charging for all\n",
      "URL: https://x.com/TeslaCharging/status/1860101088441172257\n",
      "Score: 224\n",
      "Comments: 94\n",
      "Created at (UTC): 2024-11-23 04:36:09+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "\n",
      "--- Fetching Top Posts ---\n",
      "Fetching top posts from TeslaMotors for time filter: month\n",
      "Title: Happy Halloween!\n",
      "URL: https://i.redd.it/yvnv2z3ay6yd1.jpeg\n",
      "Score: 2447\n",
      "Comments: 63\n",
      "Created at (UTC): 2024-11-01 01:16:08+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Tesla tops $1 trillion market cap\n",
      "URL: https://i.redd.it/5ok1enlonpzd1.jpeg\n",
      "Score: 1088\n",
      "Comments: 275\n",
      "Created at (UTC): 2024-11-08 17:14:40+00:00\n",
      "Text: Tesla stock has skyrocketed. Great news for the future.  ...\n",
      "----------------------------------------\n",
      "Title: New Anti-Door-Opening Feature!(highland) on version 2024.44\n",
      "URL: https://v.redd.it/gg7spar4aa2e1\n",
      "Score: 1084\n",
      "Comments: 157\n",
      "Created at (UTC): 2024-11-21 16:44:23+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Photos from our Cybertruck Shoot in Toronto\n",
      "URL: https://www.reddit.com/gallery/1gv5z5u\n",
      "Score: 1058\n",
      "Comments: 58\n",
      "Created at (UTC): 2024-11-19 19:42:45+00:00\n",
      "Text: Did a photoshoot with our new Cybertruck in Toronto last week.\n",
      "\n",
      "Shoutout to Sighlessvision on Instagram for his fantastic work.\n",
      "\n",
      "https://www.instagram.com/sightlessvision?igsh=MWdmcXl0eXN6ZmlyYw==...\n",
      "----------------------------------------\n",
      "Title: Tesla Reveals Percentage of Parts Made in North America for 2025 Models | Teslaâ€™s vehicles are, unsurprisingly, the most North American made vehicles. This specifically includes parts produced and sourced from the US and Canada for 2025 models.  \n",
      "URL: https://www.notateslaapp.com/news/2355/tesla-reveals-percentage-of-parts-made-in-north-america-for-2025-models\n",
      "Score: 993\n",
      "Comments: 87\n",
      "Created at (UTC): 2024-11-03 10:38:11+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Horse buggy next to a row of Tesla chargers \n",
      "URL: https://i.redd.it/s3llqf0gdtzd1.jpeg\n",
      "Score: 982\n",
      "Comments: 60\n",
      "Created at (UTC): 2024-11-09 05:44:25+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: V4 Supercharger ðŸ˜®â€ðŸ’¨\n",
      "URL: https://i.redd.it/wyjnhaddt3xd1.jpeg\n",
      "Score: 979\n",
      "Comments: 101\n",
      "Created at (UTC): 2024-10-26 13:39:06+00:00\n",
      "Text: Located in Caledonia, MI. Beautiful Michigan morning and perfect for trying out this incredible charger ...\n",
      "----------------------------------------\n",
      "Title: Cybertruck have arrived in Canada!\n",
      "URL: https://www.reddit.com/gallery/1ghng1s\n",
      "Score: 890\n",
      "Comments: 136\n",
      "Created at (UTC): 2024-11-02 03:15:38+00:00\n",
      "Text: First time seeing them in Canada!...\n",
      "----------------------------------------\n",
      "Title: 2024 vs. 2025 Rear Camera Design Update\n",
      "URL: https://i.redd.it/3m5pgrgqgp1e1.jpeg\n",
      "Score: 870\n",
      "Comments: 152\n",
      "Created at (UTC): 2024-11-18 18:43:59+00:00\n",
      "Text: No text available...\n",
      "----------------------------------------\n",
      "Title: Cyber cab on Display at Santana Row, CA\n",
      "URL: https://www.reddit.com/gallery/1gnpaca\n",
      "Score: 699\n",
      "Comments: 80\n",
      "Created at (UTC): 2024-11-10 01:23:59+00:00\n",
      "Text: Went to check this one out today. Looking like a MacBook on wheels ðŸ˜… I have to admit I like the design for some reason. ...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Reddit API credentials (replace these with your actual values)\n",
    "client_id = '27QbrBstNI0qx3ACSCOsAw'\n",
    "client_secret = 'L1gYXRJ3CQ0dfrXQTfoYxELkiksQdQ'\n",
    "user_agent = 'trading_co_crawler'  # Can be any descriptive name\n",
    "\n",
    "# Initialize PRAW\n",
    "# Initialize PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Function to fetch posts from the past X days\n",
    "def fetch_posts_by_days(subreddit_name, days=7):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    start_time = current_time - timedelta(days=days)\n",
    "    print(f\"Fetching posts from {subreddit_name} since {start_time.isoformat()}\")\n",
    "\n",
    "    posts = []\n",
    "    for post in subreddit.new(limit=None):\n",
    "        post_time = datetime.fromtimestamp(post.created_utc, timezone.utc)\n",
    "        if post_time >= start_time:\n",
    "            posts.append({\n",
    "                'title': post.title,\n",
    "                'url': post.url,\n",
    "                'score': post.score,\n",
    "                'comments': post.num_comments,\n",
    "                'created_utc': post_time,\n",
    "                'text': post.selftext if post.selftext else \"No text available\"\n",
    "            })\n",
    "\n",
    "    if not posts:\n",
    "        print(f\"No posts found in the subreddit '{subreddit_name}' within the last {days} days.\")\n",
    "    return posts\n",
    "\n",
    "# Function to fetch top posts using a time filter\n",
    "def fetch_top_posts(subreddit_name, time_filter='all'):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    print(f\"Fetching top posts from {subreddit_name} for time filter: {time_filter}\")\n",
    "\n",
    "    posts = []\n",
    "    for post in subreddit.top(time_filter=time_filter, limit=10):\n",
    "        post_time = datetime.fromtimestamp(post.created_utc, timezone.utc)\n",
    "        posts.append({\n",
    "            'title': post.title,\n",
    "            'url': post.url,\n",
    "            'score': post.score,\n",
    "            'comments': post.num_comments,\n",
    "            'created_utc': post_time,\n",
    "            'text': post.selftext if post.selftext else \"No text available\"\n",
    "        })\n",
    "\n",
    "    if not posts:\n",
    "        print(f\"No top posts found in the subreddit '{subreddit_name}' for time filter: {time_filter}.\")\n",
    "    return posts\n",
    "\n",
    "# Example usage\n",
    "subreddit_name = 'TeslaMotors'  # Change to a more relevant subreddit\n",
    "print(\"\\n--- Fetching Recent Posts ---\")\n",
    "recent_posts = fetch_posts_by_days(subreddit_name, days=2)\n",
    "\n",
    "for post in recent_posts:\n",
    "    print(f\"Title: {post['title']}\")\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Score: {post['score']}\")\n",
    "    print(f\"Comments: {post['comments']}\")\n",
    "    print(f\"Created at (UTC): {post['created_utc']}\")\n",
    "    print(f\"Text: {post['text'][:200]}...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n--- Fetching Top Posts ---\")\n",
    "top_posts = fetch_top_posts(subreddit_name, time_filter='month')\n",
    "\n",
    "for post in top_posts:\n",
    "    print(f\"Title: {post['title']}\")\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Score: {post['score']}\")\n",
    "    print(f\"Comments: {post['comments']}\")\n",
    "    print(f\"Created at (UTC): {post['created_utc']}\")\n",
    "    print(f\"Text: {post['text'][:200]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fetching Recent Posts ---\n",
      "Fetching posts from Crypto since 2024-11-23T01:27:41.028695+00:00\n",
      "\n",
      "--- Fetching Top Posts ---\n",
      "Fetching top posts from Crypto for time filter: month\n",
      "\n",
      "Top Posts:\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gxj6ad/new_rule_all_use_of_any_ai_llm_when_posting_must/\n",
      "Date: 2024-11-22T21:41:28+00:00\n",
      "Text: See the title.\n",
      "\n",
      "The rule is being applied due to multiple cases of users coming to us with extremely incorrect ideas about cryptography which they got from LLMs such as ChatGPT, wasting time and causing frustration because they assumed ChatGPT told the truth.\n",
      "\n",
      "Any use of any LLM, AI, neural network, or other machine learning architecture, or any equivalent computer generated response, MUST be disclosed. You must also disclose the prompt so that we can understand what you're trying to achieve and why....\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gl55ze/reminder_fheorg_fully_homomorphic_encryption_2025/\n",
      "Date: 2024-11-06T18:20:55+00:00\n",
      "Text: The deadline to submit your presentation for FHE.org 2025 is fast approachingâ€”less than two weeks left â€” November 23, 2024 (23:58 AoE)!\n",
      "\n",
      "Donâ€™t miss your chance to share your work with the FHE community in Sofia on March 25th, 2025.\n",
      "\n",
      "We welcome a wide range of submissions, including work presented at other conferences, FHE-related use cases, innovative demos, tutorials, and any other thought-provoking FHE talk ideas.\n",
      "\n",
      "Submit your work through our EasyChair server here: https://fhe.org/conferences/conference-2025/submissions\n",
      "\n",
      "Submissions should be in the form of a 2-4 page PDF document that describes your work and highlights why it should be included in FHE.org 2025.\n",
      "\n",
      "One of the main considerations for acceptance by our Program Committee is whether the talk will be of interest to the FHE audience.\n",
      "\n",
      "For more details, check the full call for presentations: https://fhe.org/conferences/conference-2025/call-for-presentations\n",
      "...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gwbdxi/apology_for_removing_my_amber256_post/\n",
      "Date: 2024-11-21T08:12:14+00:00\n",
      "Text: Dear r/crypto community,\n",
      "\n",
      "I wanted to reach out and apologize for removing my recent post about AMBER256. Upon reflection, I realized that I currently lack the necessary expertise to develop a robust cryptographic algorithm. My intention was never to spread an unsound or insecure algorithm, and I believe it's important to prevent the dissemination of potentially flawed cryptographic methods.\n",
      "\n",
      "Before I revisit this project, I plan to dedicate significant time to studying existing implementations and understanding possible attacks. My goal is to ensure that any future contributions I make are both meaningful and secure.\n",
      "\n",
      "I am sincerely sorry for any confusion or inconvenience this may have caused. I also want to thank everyone who offered support and constructive feedback. Your insights are invaluable, and I appreciate your understanding.\n",
      "\n",
      "Thank you for your patience, and I look forward to engaging with the community again once I have gained more knowledge in this field....\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gg34g3/would_the_clipper_chip_apply_to_foreign_sales_of/\n",
      "Date: 2024-10-31T01:29:23+00:00\n",
      "Text: Wouldn't that mean the Department of Commerce has keys to the entire world's communications?\n",
      "\n",
      "  \n",
      "How would the Clipper Chip apply to foreign nations?...\n",
      "----------------------------------------\n",
      "URL: https://nvlpubs.nist.gov/nistpubs/ir/2024/NIST.IR.8547.ipd.pdf\n",
      "Date: 2024-11-23T20:22:19+00:00\n",
      "Text: \n",
      "NIST has published draf IR 8547, outlining the national strategy for migrating to quantum-resistant cryptography by 2035.\n",
      "\n",
      "This draft sets 2030 as the deadline to phase out RSA, ECDSA, and EdDSA, with their complete prohibition by 2035.\n",
      "\n",
      "On behalf of the PKI Consortium (a non-profit organization), I invite you to join NIST and leading industry experts at the upcoming Post-Quantum Cryptography Conference, taking place January 15â€“16, 2025, at the Thompson Conference Center (University of Texas, Austin).\n",
      "\n",
      "The conference will feature leading experts discussing the state of quantum-resistant algorithms, the readiness of current hardware and software, and practical migration strategies. Sessions will include insights from NIST and lessons from organizations already navigating this transition.\n",
      "\n",
      "Registration is free for both in-person and remote attendees. Sign up here: https://pkic.org/register\n",
      "\n",
      "For more information, visit the conference website: https://pkic.org/events/2025/pqc-conference-austin-us/\n",
      "\n",
      "Are you ready for this pivotal moment in cryptographyâ€™s history?...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gu27pr/weekly_cryptography_community_and_meta_thread/\n",
      "Date: 2024-11-18T11:00:26+00:00\n",
      "Text: Welcome to /r/crypto's weekly community thread!\n",
      "\n",
      "This thread is a place where people can freely discuss broader topics (but NO cryptocurrency spam, see the sidebar), perhaps even share some memes (but please keep the worst offenses contained to /r/shittycrypto), engage with the community, discuss meta topics regarding the subreddit itself (such as discussing the customs and subreddit rules, etc), etc.\n",
      "\n",
      "Keep in mind that the standard reddiquette rules still apply, i.e. be friendly and constructive!\n",
      "\n",
      "So, what's on your mind? Comment below!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gopnf4/weekly_cryptography_community_and_meta_thread/\n",
      "Date: 2024-11-11T11:00:22+00:00\n",
      "Text: Welcome to /r/crypto's weekly community thread!\n",
      "\n",
      "This thread is a place where people can freely discuss broader topics (but NO cryptocurrency spam, see the sidebar), perhaps even share some memes (but please keep the worst offenses contained to /r/shittycrypto), engage with the community, discuss meta topics regarding the subreddit itself (such as discussing the customs and subreddit rules, etc), etc.\n",
      "\n",
      "Keep in mind that the standard reddiquette rules still apply, i.e. be friendly and constructive!\n",
      "\n",
      "So, what's on your mind? Comment below!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gmcwk1/webapp_encryption_at_rest/\n",
      "Date: 2024-11-08T07:11:17+00:00\n",
      "Text: im working on a javascript UI framework for personal projects and im trying to create something like a React-hook that handles \"encrypted at rest\".\n",
      "\n",
      "the react-hook is described in more detail [here](https://positive-intentions.com/blog/async-state-management). id like to extend its functionality to have encrypted persistant data. my approach is the following and it would be great if you could follow along and let me know if im doing something wrong. all advice is apprciated.\n",
      "\n",
      "im using indexedDB to store the data. i created some basic functionality to automatically persist and rehydrate data. im now investigating password-encrypting the data with javascript using the browser cryptography api.\n",
      "\n",
      "i have a PR [here](https://github.com/positive-intentions/dim/pull/8) you can test out on codespaces or clone, but tldr: i encrypt before saving and decrypt when loading. this seems to be working as expected. i will also encrypt/decrypt the event listeners im using and this should keep it safe from anything like browser extensions from listening to events.\n",
      "\n",
      "the password is something the user will have to put in themselves at part of some init() process. i havent created an input for this yet, so its hardcoded. this is then used to encrypt/decrypt the data.\n",
      "\n",
      "i would persist the unencrypted salt to indexedDB because this is then used to generate the key.\n",
      "\n",
      "i think i am almost done with this functionality, but id like advice on anything ive overlooked or things too keep-in-mind. id like to make the storage as secure as possible.\n",
      "\n",
      "  \n",
      "\\---\n",
      "\n",
      "  \n",
      "Edit 11/11/2024:\n",
      "\n",
      "I created some updates to the WIP pull-request. The behavior is as follows.\n",
      "\n",
      "\\- The user is prompted for a password if one isn't provided programmatically.\n",
      "\n",
      "\\- This will allow for developers to create a custom password prompts in their application. The default fallback is to use a JavaScript prompt().\n",
      "\n",
      "\\- It also seems possible to enable something like \"fingerprint/face encryption\" for some devices using the webauthn api. (This works, but the functionality is a bit flaky and needs to be \"ironed out\" before rolling out.)\n",
      "\n",
      "\\- Using AES-GCM with 1mil iterations of PBKDF2 to derive the key from the password.\n",
      "\n",
      "\\- The iterations can be increased in exchange for slower performance. It isn't currently configurable, but it might be in the future.\n",
      "\n",
      "\\- The salt and AAD need to be deterministic and so to simplify user input, the salt as AAD are derived as the sha256 hash of the password. (Is this a good idea?)\n",
      "\n",
      "The latest version of the code can be seen in the PR: [https://github.com/positive-intentions/dim/pull/9](https://github.com/positive-intentions/dim/pull/9)...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gu27po/monthly_cryptography_wishlist_thread/\n",
      "Date: 2024-11-18T11:00:26+00:00\n",
      "Text: This is another installment in a series of monthly recurring cryptography wishlist threads.\n",
      "\n",
      "The purpose is to let people freely discuss what future developments they like to see in fields related to cryptography, including things like algorithms, cryptanalysis, software and hardware implementations, usable UX, protocols and more.\n",
      "\n",
      "So start posting what you'd like to see below!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gjbl33/weekly_cryptography_community_and_meta_thread/\n",
      "Date: 2024-11-04T11:00:22+00:00\n",
      "Text: Welcome to /r/crypto's weekly community thread!\n",
      "\n",
      "This thread is a place where people can freely discuss broader topics (but NO cryptocurrency spam, see the sidebar), perhaps even share some memes (but please keep the worst offenses contained to /r/shittycrypto), engage with the community, discuss meta topics regarding the subreddit itself (such as discussing the customs and subreddit rules, etc), etc.\n",
      "\n",
      "Keep in mind that the standard reddiquette rules still apply, i.e. be friendly and constructive!\n",
      "\n",
      "So, what's on your mind? Comment below!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gts69k/key_ring_file_format/\n",
      "Date: 2024-11-18T00:32:50+00:00\n",
      "Text: I'm a professional software engineer, and I've written software to manage user-generated keys for a bespoke system in the past. The general gist was vary the encoding of the key data itself while associating it with a human-readable label in a flat file that was subsequently encrypted before being written to disk, and encrypted in RAM, only after being fully loaded, by a key that was part of the key management program. That key was not stored in plaintext in the program executable. It was stored in chunks with about 10 x the actual amount of data needed to store the key, interspersed randomly, and only assembled together, programmaticly, and in random fashion, and decoded into the actual key immediately before it's needed, and as soon as the operation is over, it's memory is zeroed back out until the key is needed again. If anyone had the program source code, they could easily implement a new master key and create their own key ring eco-system, but it was the only way I could come up with to be able to store several keys persistently, but securely, while allowing the user to manage their own keys as they saw fit.\n",
      "\n",
      "Surely, there are better ways to manage user keys. PGP has a keyring. GPG has a keyring. Even GNOME has a keyring. How are they designed to keep keys persistently, but securely? Are there any design documents or research papers that describe such a system?...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gjbmz8/mlkem_encapsulate_nonrandom_bytes/\n",
      "Date: 2024-11-04T11:03:26+00:00\n",
      "Text:     I am not a cryptographer, but I am trying to use cryptographic libraries and would like to do it safely. Unfortunately, for my use case it seems to require using them in a non-standard way. The APIs don't seem to fit my use case straight-forward.\n",
      "    \n",
      "    I was curious if it was theoretically possible and safe to use the ML-Kem encapsulation key to encapsulate a non-random value as the shared secret. \n",
      "    \n",
      "    What I actually am wanting to do is use the encapsulation key to encapsulate an x25519 public key into the cipher text for a mutual authenticated hybrid setup. The decrypted public key would be used to derive a shared secret using the x25519 process. \n",
      "    \n",
      "    If this is possible, the reason I think this is safe logically, not cryptographically, is this. Suppose ML-Kem is found to be broken, this is no weaker than directly sharing the EC public key which is far safer than directly sharing the raw symmetric key. If however, it is not and EC is defeated by quantum, the 'public' key is never shared publicly, so it should still be 'safe' as neither the public nor private keys are exposed. The only scenario I see that opens exposure is if both algorithms are broken in which case it's no worse than anything else that only uses both. The advantage is that it doesn't share the EC key publicly and you save 32 bytes. If however you include a 32byte hash of the EC public key in the shared message, the recipient could verify that the decryption was successful without an additional round trip and still using the same message size of a random value encapsulated and an additional x25519 key appended. Of course to be mutual, keys/ciphers need to be exchanged in the opposite direction as well.\n",
      "    \n",
      "    I am likely missing something very important, so if this is a bad idea, please explain why. If it is not possible, I would also like to know why. Please don't just tell me to use standard APIs (even if that's what I should do and will if necessary) because I don't learn anything that way.\n",
      "    \n",
      "    Thanks!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gdz7ll/weekly_cryptography_community_and_meta_thread/\n",
      "Date: 2024-10-28T11:00:16+00:00\n",
      "Text: Welcome to /r/crypto's weekly community thread!\n",
      "\n",
      "This thread is a place where people can freely discuss broader topics (but NO cryptocurrency spam, see the sidebar), perhaps even share some memes (but please keep the worst offenses contained to /r/shittycrypto), engage with the community, discuss meta topics regarding the subreddit itself (such as discussing the customs and subreddit rules, etc), etc.\n",
      "\n",
      "Keep in mind that the standard reddiquette rules still apply, i.e. be friendly and constructive!\n",
      "\n",
      "So, what's on your mind? Comment below!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gwfm17/can_a_digital_signature_on_some_data_be_replaced/\n",
      "Date: 2024-11-21T12:55:30+00:00\n",
      "Text: I am going to ask a rather stupid question for which I apologize in advance, but I'm sort of losing my head at this point.\n",
      "\n",
      "I am working on an encryption system where two parties are required to authenticate themselves to one another and subsequently perform a key exchange.\n",
      "\n",
      "The procedure is as follows:\n",
      "\n",
      "1. Assume Alice and Bob both generate a secret one-time token.\n",
      "2. Alice generates an ephemeral key pair and signs the token with her private key.\n",
      "3. Alice sends the signature over to Bob along with her public key.\n",
      "4. Bob verifies the signature and can now trust Alice's public key.\n",
      "\n",
      "Now let's say a malicious actor, Charlie wants to authenticate his public key to Bob, and Charlie has managed to intercept the signature sent by Alice.\n",
      "\n",
      "Can Charlie destroy Alice's original signature, sign the token with his own key, and \"replay\" it to Bob?\n",
      "\n",
      "If this is possible, how can one avoid such a situation?\n",
      "\n",
      "Edit: So it turns out there's a term for exactly what I was trying to achieve, called PAKE. Thanks to u/cryptoam1, u/Natanael_L, and u/djao for pointing it out, and sorry for asking a question without first doing thorough research, but I ended up learning something new. Reddit goated as always!...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gw6h5o/candidate_for_simple_csprngultralightweight/\n",
      "Date: 2024-11-21T03:12:36+00:00\n",
      "Text: Hello everyone. Some time ago I created efficient pseudo-random number generators based on Collatz-like functions:\n",
      "\n",
      "[https://www.reddit.com/r/RNG/comments/19a2q24/collatzweyl\\_generators/](https://www.reddit.com/r/RNG/comments/19a2q24/collatzweyl_generators/)\n",
      "\n",
      "[https://arxiv.org/pdf/2312.17043](https://arxiv.org/pdf/2312.17043)\n",
      "\n",
      "One of the simplest of them is the Collatz-Weyl generator:\n",
      "\n",
      "    static __uint128_t x, weyl, s; // s must be odd\n",
      "    \n",
      "    bool Collatz_Weyl(void){\n",
      "      if(x % 2 == 1){\n",
      "      x = (3*x+1)/2;}\n",
      "      else{\n",
      "      x = x/2;}\n",
      "      x ^= (weyl += s);\n",
      "    \n",
      "      return x & 1;\n",
      "    }\n",
      "\n",
      "We can consider `s` as a key and the resulting single bit could be used as a cryptographically secure bit to XOR with plaintext, as in a typical strem cipher. Every iteration of presented function generate only 1 bit, similar to Blum Blum Shub. It can be used as a extremely light-weight stream cipher, the whole code is just (constant-time implementation):\n",
      "\n",
      "    x = (-(x & 1) & (x + ((x + 1) >> 1)) | ~-(x & 1) & (x >> 1)) ^ (weyl += s);\n",
      "    return x & 1;\n",
      "\n",
      "In the linked thread I provide a certain method of attack, when XORation with weyl sequence is replaced by addition (toy version), using extended Euclidean algorithm and by hacking somehow at least some bits of the key or the state of the generator. In the main version using XOR, such an attack is not even possible. I did not consider any other types of attacks than those mentioned here, i.e.:  \n",
      "\\- dedicated type of attack based on known-plaintext attack on toy version,  \n",
      "\\- related key attacks,  \n",
      "\\- timing attacks,  \n",
      "\\- theoretically possible birthday attacks (see my comment in this thread).\n",
      "\n",
      "Perhaps such a stream cipher could find applications on extremely resource-constrained devices. However, I don't know if I'll find the motivation to write a separate paper on this topic and if it's even worth it. I don't feel competent enough in the subject of cryptography (so I probably won't take on this task alone), I wasn't even able to get the opinion of anyone from the industry (it's a pretty closed industry, and I don't come from the crypto industry, I did it as a hobby).\n",
      "\n",
      "Here is constant-time code, with some additional measures to prevent related-key attacks and to fill the key:\n",
      "\n",
      "    #include <bitset>\n",
      "    #include<iostream>\n",
      "    \n",
      "    //the initializer is there to fill the entire key s, additionally initializing s in this way helps to avoid recognizing keys with the same number of zeros, e.g. by adding 2^n to the key, which is important for the security of the algorithm, because it can lead to the generation of weaker x; this initialization is also to prevent key from being determined by simple modulo subtraction from weyl, if an attacker were to for example hack s and weyl, he could determine an initial value of weyl which in this case would not lead him to key\n",
      "    \n",
      "    struct xws { __uint128_t x, weyl, s; };\n",
      "    \n",
      "    struct xws initializer(__uint128_t x_init, __uint128_t weyl_init, const __uint128_t s_init)\n",
      "    {\n",
      "        __uint128_t x = 0;\n",
      "        __uint128_t weyl = 0;\n",
      "        __uint128_t s = 0;\n",
      "    \n",
      "        for (int i = 0; i < 128; i++)\n",
      "        {\n",
      "            x_init = (-(x_init & 1) & (x_init + ((x_init + 1) >> 1)) | ~- (x_init & 1) & (x_init >> 1)) ^ (weyl_init += s_init);\n",
      "            x += (x_init & 1) << i;\n",
      "        }\n",
      "        for (int i = 0; i < 128; i++)\n",
      "        {\n",
      "            x_init = (-(x_init & 1) & (x_init + ((x_init + 1) >> 1)) | ~- (x_init & 1) & (x_init >> 1)) ^ (weyl_init += s_init);\n",
      "            weyl += (x_init & 1) << i;\n",
      "        }\n",
      "        for (int i = 0; i < 128; i++)\n",
      "        {\n",
      "            x_init = (-(x_init & 1) & (x_init + ((x_init + 1) >> 1)) | ~- (x_init & 1) & (x_init >> 1)) ^ (weyl_init += s_init);\n",
      "            s += (x_init & 1) << i;\n",
      "        }\n",
      "        return xws{x, weyl, s | 1 };\n",
      "    }\n",
      "    \n",
      "    struct xw { __uint128_t x, weyl; };\n",
      "    \n",
      "    //skip is to avoid correlated bitstream results for consecutive s, given the same x and weyl or for example for consecutive weyl, given the same s and x, etc.\n",
      "    \n",
      "    struct xw skip(__uint128_t x, __uint128_t weyl, const __uint128_t s)\n",
      "    {\n",
      "      for (int i = 0; i < 128; i++)\n",
      "      {\n",
      "        x = (-(x & 1) & (x + ((x + 1) >> 1)) | ~- (x & 1) & (x >> 1)) ^ (weyl += s);\n",
      "      }\n",
      "      return xw{ x, weyl };\n",
      "    }\n",
      "    \n",
      "    __uint128_t next(__uint128_t& x, __uint128_t& weyl, const __uint128_t& s)\n",
      "    {\n",
      "      __uint128_t v = 0;\n",
      "    \n",
      "      for (int i = 0; i < 128; i++)\n",
      "      {\n",
      "        x = (-(x & 1) & (x + ((x + 1) >> 1)) | ~-(x & 1) & (x >> 1)) ^ (weyl += s);\n",
      "        v += (x & 1) << i; // here we build 128-bit numbers from a single bit returned sequentially by the generator\n",
      "      }\n",
      "      return v;\n",
      "    }\n",
      "    \n",
      "    \n",
      "    int main()\n",
      "    {\n",
      "      const __uint128_t key = 12345678910111213; //the key must be odd\n",
      "      const __uint128_t x_init = key, weyl_init = key, s_init = key; //all these variables must be secret, s_init must be odd\n",
      "    \n",
      "        xws initialization = initializer(x_init, weyl_init, s_init);\n",
      "        __uint128_t x = initialization.x;\n",
      "        __uint128_t weyl = initialization.weyl;\n",
      "        __uint128_t s = initialization.s;\n",
      "    \n",
      "        xw skipping = skip(x, weyl, s);\n",
      "        x = skipping.x;\n",
      "        weyl = skipping.weyl;\n",
      "        \n",
      "        __uint128_t result = 0;\n",
      "    \n",
      "      for(int i=0; i<100; i++)\n",
      "      {\n",
      "    \n",
      "        result = next(x, weyl, s);\n",
      "    \n",
      "        std::cout << std::bitset<64>(result >> 64) << \"\\n\";\n",
      "        std::cout << std::bitset<64>(result) << \"\\n\";\n",
      "      }\n",
      "      return 0;\n",
      "    }\n",
      "\n",
      "An additional feature is backtracking resistance, since it is not based on a bijective function, you must guess at least one bit in each iteration to reverse it, see: https://arxiv.org/abs/1801.05079. What do you think?...\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gjgvbl/how_to_apply_pohlig_hellman_using_a_very_limited/\n",
      "Date: 2024-11-04T15:25:21+00:00\n",
      "Text: So I was reading about [this paper](https://eprint.iacr.org/2024/1321). The underlying idea is to lift the discrete logarithm problem to *primeâˆ’1* for prime curves or *orderâˆ’1* for binary curves since most elliptic curves only have small factors in that case. But [their babyâ€‘step giantâ€‘step variant seems to only work when the private key already lie in a specific subgroup](https://github.com/cysecud/ecc_weak_keys/blob/master/gp_code/alg.gp#L21). That isÂ : no indication is made on how to move the key to each underlying order subgroup.  \n",
      "And of course, using exponentiations to solve the problem isnâ€™t a reason that allow building an index calculus algorithmâ€¦ \n",
      "\n",
      "If I understand correctly (or maybe Iâ€™m wrong), being able to use Pohlig Hellman would require using auxiliary inputs **as proposed by Cheon**Â : but in my case, I only have 48 of them over the extension of a pairing friendly curve of large characteristic....\n",
      "----------------------------------------\n",
      "URL: https://www.reddit.com/r/crypto/comments/1gyb7uj/searching_a_program_that_output_in_hex/\n",
      "Date: 2024-11-23T22:07:10+00:00\n",
      "Text: Hello!\n",
      "\n",
      "i am a Ham radio operator and i want to experiment sending encrypted traffic\\* using JS8call. its a program sending/receiving **UPPERCASE** letters or **numbers** at about 8-40WPM. i need a something using symmetrical encryption that i can easily copy and paste text out off. JS8call already has checksum inside that enable the users to automatically see if the message is intact or not. so i dont need signatures, verification and stuff.\n",
      "\n",
      "if possible compatible with Windows and Linux? with a **GUI**\n",
      "\n",
      "i searched alot online for hours without sucess. it seem i need something that can convert the output to **HEX** (also recognize this to decode). there is alot of very interesting stuff on Github, but its mostly webpage based or command line. i wish somebody knows of an existing solution.\n",
      "\n",
      "\\*encryption on Ham bands is legal in my country. i just need to make public the mode and password used....\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Reddit API credentials\n",
    "client_id = '27QbrBstNI0qx3ACSCOsAw'\n",
    "client_secret = 'L1gYXRJ3CQ0dfrXQTfoYxELkiksQdQ'\n",
    "user_agent = 'trading_co_crawler'\n",
    "\n",
    "# Initialize PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Function to fetch posts with actual text\n",
    "def fetch_posts_with_text(subreddit_name, days=5, time_filter=\"month\"):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    start_time = current_time - timedelta(days=days)\n",
    "\n",
    "    # Fetch recent posts\n",
    "    print(\"--- Fetching Recent Posts ---\")\n",
    "    print(f\"Fetching posts from {subreddit_name} since {start_time.isoformat()}\")\n",
    "    recent_posts = [\n",
    "        {\n",
    "            'url': post.url,\n",
    "            'date': datetime.fromtimestamp(post.created_utc, timezone.utc).isoformat(),\n",
    "            'text': post.selftext\n",
    "        }\n",
    "        for post in subreddit.new(limit=None)\n",
    "        if post.selftext and post.selftext.strip()  # Exclude posts without meaningful text\n",
    "    ]\n",
    "\n",
    "    # Fetch top posts\n",
    "    print(\"\\n--- Fetching Top Posts ---\")\n",
    "    print(f\"Fetching top posts from {subreddit_name} for time filter: {time_filter}\")\n",
    "    top_posts = [\n",
    "        {\n",
    "            'url': post.url,\n",
    "            'date': datetime.fromtimestamp(post.created_utc, timezone.utc).isoformat(),\n",
    "            'text': post.selftext\n",
    "        }\n",
    "        for post in subreddit.top(time_filter=time_filter)\n",
    "        if post.selftext and post.selftext.strip()  # Exclude posts without meaningful text\n",
    "    ]\n",
    "\n",
    "    return recent_posts, top_posts\n",
    "\n",
    "# Example usage\n",
    "subreddit_name = 'Crypto'\n",
    "days = 2  # Fetch posts from the last 2 days\n",
    "recent_posts, top_posts = fetch_posts_with_text(subreddit_name, days=days)\n",
    "\"\"\"\n",
    "# Display results\n",
    "print(\"\\nRecent Posts:\")\n",
    "for post in recent_posts:\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Date: {post['date']}\")\n",
    "    print(f\"Text: {post['text']}...\")  # Display first 200 characters of the text\n",
    "    print(\"-\" * 40)\n",
    "\"\"\"\n",
    "print(\"\\nTop Posts:\")\n",
    "for post in top_posts:\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Date: {post['date']}\")\n",
    "    print(f\"Text: {post['text']}...\")  # Display first 200 characters of the text\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0     Super Bowl LIX Pregame Entertainment Announced   \n",
      "1  Ninepoint Partners Announces Final November 20...   \n",
      "2  Stallion Uranium Announces Conditional Accepta...   \n",
      "3  XRAY INVESTOR ALERT: Bronstein, Gewirtz & Gros...   \n",
      "4  XRX INVESTOR ALERT: Bronstein, Gewirtz & Gross...   \n",
      "\n",
      "                                                 url   time_published  \\\n",
      "0  https://www.benzinga.com/pressreleases/24/11/n...  20241128T213000   \n",
      "1  https://www.benzinga.com/pressreleases/24/11/g...  20241128T211902   \n",
      "2  https://www.benzinga.com/pressreleases/24/11/g...  20241128T210040   \n",
      "3  https://www.benzinga.com/pressreleases/24/11/g...  20241128T210000   \n",
      "4  https://www.benzinga.com/pressreleases/24/11/g...  20241128T210000   \n",
      "\n",
      "            authors                                            summary  \\\n",
      "0      [PRNewswire]  Jon Batiste, Trombone Shorty, Lauren Daigle an...   \n",
      "1  [Globe Newswire]  TORONTO, Nov. 28, 2024 ( GLOBE NEWSWIRE ) -- N...   \n",
      "2  [Globe Newswire]  VANCOUVER, British Columbia, Nov. 28, 2024 ( G...   \n",
      "3  [Globe Newswire]  NEW YORK, Nov. 28, 2024 ( GLOBE NEWSWIRE ) -- ...   \n",
      "4  [Globe Newswire]  NEW YORK, Nov. 28, 2024 ( GLOBE NEWSWIRE ) -- ...   \n",
      "\n",
      "                                        banner_image    source  \\\n",
      "0  https://mma.prnewswire.com/media/2569025/Super...  Benzinga   \n",
      "1  https://www.benzinga.com/next-assets/images/sc...  Benzinga   \n",
      "2  https://www.benzinga.com/next-assets/images/sc...  Benzinga   \n",
      "3  https://www.benzinga.com/next-assets/images/sc...  Benzinga   \n",
      "4  https://www.benzinga.com/next-assets/images/sc...  Benzinga   \n",
      "\n",
      "  category_within_source     source_domain  \\\n",
      "0                General  www.benzinga.com   \n",
      "1                   News  www.benzinga.com   \n",
      "2                Markets  www.benzinga.com   \n",
      "3                   News  www.benzinga.com   \n",
      "4                   News  www.benzinga.com   \n",
      "\n",
      "                                              topics  overall_sentiment_score  \\\n",
      "0  [{'topic': 'Real Estate & Construction', 'rele...                 0.408544   \n",
      "1  [{'topic': 'Financial Markets', 'relevance_sco...                 0.262818   \n",
      "2                                                 []                 0.267653   \n",
      "3  [{'topic': 'Life Sciences', 'relevance_score':...                 0.055921   \n",
      "4  [{'topic': 'Technology', 'relevance_score': '1...                -0.012240   \n",
      "\n",
      "  overall_sentiment_label                                   ticker_sentiment  \n",
      "0                 Bullish  [{'ticker': 'KO', 'relevance_score': '0.020794...  \n",
      "1        Somewhat-Bullish                                                 []  \n",
      "2        Somewhat-Bullish  [{'ticker': 'SASKF', 'relevance_score': '0.048...  \n",
      "3                 Neutral  [{'ticker': 'XRAY', 'relevance_score': '0.2863...  \n",
      "4                 Neutral  [{'ticker': 'XRX', 'relevance_score': '0.61374...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Import required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Step 3: Set your Alpha Vantage API key\n",
    "api_key = \"8USSUHG9CIPYSADT\"  # Replace with your Alpha Vantage API key\n",
    "\n",
    "# Step 4: Define the function to fetch news\n",
    "def fetch_news(topic):\n",
    "    \"\"\"\n",
    "    Fetch news related to a specific topic using Alpha Vantage API.\n",
    "    \n",
    "    :param topic: The keyword or topic to search for (e.g., \"Bitcoin\", \"Amazon\").\n",
    "    :return: A DataFrame containing the news data.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"keywords\": topic,\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Convert the 'feed' key in the JSON response to a pandas DataFrame\n",
    "        if \"feed\" in data:\n",
    "            news_df = pd.DataFrame(data[\"feed\"])\n",
    "            return news_df\n",
    "        else:\n",
    "            print(\"No news data found for this topic.\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Step 5: Fetch news data for a specific topic\n",
    "topic = \"Bitcoin\"  # Replace with your topic of interest\n",
    "news_df = fetch_news(topic)\n",
    "\n",
    "# Step 6: Display the news DataFrame\n",
    "if not news_df.empty:\n",
    "    print(news_df.head())\n",
    "else:\n",
    "    print(\"No data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date                                               link  \\\n",
      "0  2024-12-03 23:48:24  https://www.benzinga.com/news/global/24/12/423...   \n",
      "1  2024-12-03 23:43:43  https://decrypt.co/294645/bitcoin-altcoins-dog...   \n",
      "2  2024-12-03 23:41:27  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "3  2024-12-03 23:36:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "4  2024-12-03 23:35:48  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "5  2024-12-03 23:30:07  https://www.scmp.com/business/banking-finance/...   \n",
      "6  2024-12-03 23:30:00  https://www.globenewswire.com/news-release/202...   \n",
      "7  2024-12-03 23:22:00  https://www.fool.com/investing/2024/12/03/why-...   \n",
      "8  2024-12-03 23:19:10  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "9  2024-12-03 23:14:00  https://www.globenewswire.com/news-release/202...   \n",
      "10 2024-12-03 23:13:39  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "11 2024-12-03 23:13:00  https://www.fool.com/investing/2024/12/03/why-...   \n",
      "12 2024-12-03 23:13:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "13 2024-12-03 23:09:16  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "14 2024-12-03 23:09:07  https://www.benzinga.com/general/social-media/...   \n",
      "15 2024-12-03 23:09:00  https://www.globenewswire.com/news-release/202...   \n",
      "16 2024-12-03 23:06:22  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "17 2024-12-03 23:06:00  https://www.globenewswire.com/news-release/202...   \n",
      "18 2024-12-03 23:04:53  https://decrypt.co/294635/illuvium-ethereum-ga...   \n",
      "19 2024-12-03 23:00:32  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "20 2024-12-03 23:00:00  https://www.globenewswire.com/news-release/202...   \n",
      "21 2024-12-03 22:58:44  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "22 2024-12-03 22:58:32  https://www.benzinga.com/general/gaming/24/12/...   \n",
      "23 2024-12-03 22:53:00  https://www.globenewswire.com/news-release/202...   \n",
      "24 2024-12-03 22:49:03  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "25 2024-12-03 22:48:38  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "26 2024-12-03 22:47:21  https://decrypt.co/294632/grayscale-files-to-c...   \n",
      "27 2024-12-03 22:41:59  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "28 2024-12-03 22:41:16  https://www.benzinga.com/general/entertainment...   \n",
      "29 2024-12-03 22:41:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "30 2024-12-03 22:41:00  https://www.globenewswire.com/news-release/202...   \n",
      "31 2024-12-03 22:40:00  https://www.globenewswire.com/news-release/202...   \n",
      "32 2024-12-03 22:32:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "33 2024-12-03 22:31:20  https://www.fool.com/investing/2024/12/03/3-re...   \n",
      "34 2024-12-03 22:30:13  https://www.cnbc.com/2024/12/03/florida-prison...   \n",
      "35 2024-12-03 22:30:00  https://www.globenewswire.com/news-release/202...   \n",
      "36 2024-12-03 22:30:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "37 2024-12-03 22:27:00  https://www.benzinga.com/pressreleases/24/12/n...   \n",
      "38 2024-12-03 22:21:16  https://www.benzinga.com/markets/cryptocurrenc...   \n",
      "39 2024-12-03 22:18:16  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "40 2024-12-03 22:18:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "41 2024-12-03 22:18:00  https://www.globenewswire.com/news-release/202...   \n",
      "42 2024-12-03 22:06:00  https://www.benzinga.com/pressreleases/24/12/n...   \n",
      "43 2024-12-03 22:05:00  https://www.globenewswire.com/news-release/202...   \n",
      "44 2024-12-03 22:05:00  https://www.globenewswire.com/news-release/202...   \n",
      "45 2024-12-03 22:04:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "46 2024-12-03 22:04:00  https://www.globenewswire.com/news-release/202...   \n",
      "47 2024-12-03 22:03:21  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "48 2024-12-03 22:03:00  https://www.globenewswire.com/news-release/202...   \n",
      "49 2024-12-03 22:00:30  https://www.benzinga.com/general/space/24/12/4...   \n",
      "\n",
      "                                                 text  \n",
      "0   Key Stocks, ETF To Watch As French Government ...  \n",
      "1   As Bitcoin Hovers Around Its All-Time High, Tr...  \n",
      "2   Xerox Holdings Corporation Investors: Please c...  \n",
      "3   ROSEN, LEADING INVESTOR COUNSEL, Encourages Cu...  \n",
      "4   Quanterix Corporation Investors: Company Inves...  \n",
      "5   China M&A deal volume to bottom out this year,...  \n",
      "6   American Hotel Income Properties REIT LP Annou...  \n",
      "7                   Why Accenture Stock Slumped Today  \n",
      "8   Robbins LLP Urges XRX Stockholders with Large ...  \n",
      "9   Dominion Lending Centres Inc. Receives Shareho...  \n",
      "10  Customers Bancorp, Inc. Investors: Please cont...  \n",
      "11  Why Trump Media and Technology Stock Slipped 1...  \n",
      "12  ROSEN, THE FIRST FILING FIRM, Encourages Visa ...  \n",
      "13  Skyharbour Announces Upsized Private Placement...  \n",
      "14  Threads Takes On X, Bluesky With New Search Op...  \n",
      "15  Skyharbour Announces Upsized Private Placement...  \n",
      "16  Robbins LLP Urges WOLF Stockholders with Large...  \n",
      "17  POET Technologies Completes US$25 Million Regi...  \n",
      "18  'Illuvium Beyond' Ethereum Game Reveals Casio ...  \n",
      "19  Gatos Silver Announces Date of Special Meeting...  \n",
      "20  Gatos Silver Announces Date of Special Meeting...  \n",
      "21  Dentsply Sirona, Inc. Investors: Please contac...  \n",
      "22  Gamers Now Watch More Than They Play - How Pub...  \n",
      "23  Sprott Focus Trust, Inc.  ( Nasdaq-FUND )  Dec...  \n",
      "24  Robbins LLP Urges V Stockholders with Large Lo...  \n",
      "25  Robbins LLP Urges PACS Stockholders with Large...  \n",
      "26  Grayscale Files to Convert Solana Trust into E...  \n",
      "27  Algoma Steel Group to Participate in the Inaug...  \n",
      "28  'Squid Game' Season 2 Includes New Games, Cont...  \n",
      "29  ROSEN, TOP-RANKED INVESTOR COUNSEL, Encourages...  \n",
      "30  Algoma Steel Group to Participate in the Inaug...  \n",
      "31  Eagle Bancorp, Inc. Announces Registered Excha...  \n",
      "32  ROSEN, SKILLED INVESTOR COUNSEL, Encourages Ch...  \n",
      "33  3 Reasons to Buy Nvidia Stock as the UBS Globa...  \n",
      "34  Florida woman who led $200 million Ponzi schem...  \n",
      "35  Brookfield Commits to Growing Investment in Fr...  \n",
      "36  Brookfield Commits to Growing Investment in Fr...  \n",
      "37  Regal Cineworld Announces Refinancing of Term ...  \n",
      "38  Bitcoin, Ethereum, Dogecoin Hold Steady, Trade...  \n",
      "39  Procaps Group Announces Financing, Shareholder...  \n",
      "40  ACHC DEADLINE NOTICE: ROSEN, A GLOBAL AND LEAD...  \n",
      "41  Procaps Group Announces Financing, Shareholder...  \n",
      "42  Ticket Market to grow by USD 228.52 billion  (...  \n",
      "43  Ready Capital Corporation Announces Pricing of...  \n",
      "44  Diversified Royalty Corp. Announces December 2...  \n",
      "45  Tavia Acquisition Corp. Announces Pricing of $...  \n",
      "46  Tavia Acquisition Corp. Announces Pricing of $...  \n",
      "47  Navitas Semiconductor Appoints Dr. Ranbir Sing...  \n",
      "48  Navitas Semiconductor Appoints Dr. Ranbir Sing...  \n",
      "49  Intuitive Machines Stock Falls After Hours: He...  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Step 3: Set your Alpha Vantage API key\n",
    "api_key = \"8USSUHG9CIPYSADT\"  # Replace with your Alpha Vantage API key\n",
    "\n",
    "# Step 4: Define the function to fetch and filter news\n",
    "def fetch_filtered_news(topic, days):\n",
    "    \"\"\"\n",
    "    Fetch news related to a specific topic using Alpha Vantage API and filter by date.\n",
    "    \n",
    "    :param topic: The keyword or topic to search for (e.g., \"Bitcoin\", \"Amazon\").\n",
    "    :param days: Number of previous days to filter the news.\n",
    "    :return: A DataFrame containing filtered news with date, link, and text.\n",
    "    \"\"\"\n",
    "    # Define the API endpoint and parameters\n",
    "    url = f\"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"keywords\": topic,\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Ensure the response contains news data\n",
    "        if \"feed\" in data:\n",
    "            # Convert the 'feed' key in the JSON response to a pandas DataFrame\n",
    "            news_df = pd.DataFrame(data[\"feed\"])\n",
    "            \n",
    "            # Extract required columns: 'time_published', 'url', and 'title'\n",
    "            news_df = news_df.rename(columns={\"time_published\": \"date\", \"url\": \"link\", \"title\": \"text\"})\n",
    "            news_df = news_df[[\"date\", \"link\", \"text\"]]\n",
    "            \n",
    "            # Convert date column to datetime\n",
    "            news_df[\"date\"] = pd.to_datetime(news_df[\"date\"], format=\"%Y%m%dT%H%M%S\")\n",
    "            \n",
    "            # Filter rows by the specified number of previous days\n",
    "            cutoff_date = datetime.now() - timedelta(days=days)\n",
    "            filtered_df = news_df[news_df[\"date\"] >= cutoff_date]\n",
    "            \n",
    "            return filtered_df\n",
    "        else:\n",
    "            print(\"No news data found for this topic.\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Step 5: Fetch and filter news data for a specific topic\n",
    "topic = \"Bitcoin\"  # Replace with your topic of interest\n",
    "days = 7  # Replace with the number of previous days to filter\n",
    "filtered_news_df = fetch_filtered_news(topic, days)\n",
    "\n",
    "# Step 6: Display the filtered news DataFrame\n",
    "if not filtered_news_df.empty:\n",
    "    print(filtered_news_df)\n",
    "else:\n",
    "    print(\"No data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-28 22:15:00</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>Middlefield Announces Intention to Revise Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-28 22:12:00</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>Brompton Lifeco Split Corp. Announces Class A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-28 22:10:00</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>Middlefield Announces Intention to Revise Name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-28 22:05:00</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>Petrus Resources Announces Implementation of D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-28 22:00:00</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>NioBay Announces a New Member to Its Board of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                               link  \\\n",
       "0 2024-11-28 22:15:00  https://www.globenewswire.com/news-release/202...   \n",
       "1 2024-11-28 22:12:00  https://www.globenewswire.com/news-release/202...   \n",
       "2 2024-11-28 22:10:00  https://www.globenewswire.com/news-release/202...   \n",
       "3 2024-11-28 22:05:00  https://www.globenewswire.com/news-release/202...   \n",
       "4 2024-11-28 22:00:00  https://www.globenewswire.com/news-release/202...   \n",
       "\n",
       "                                                text  \n",
       "0  Middlefield Announces Intention to Revise Name...  \n",
       "1  Brompton Lifeco Split Corp. Announces Class A ...  \n",
       "2  Middlefield Announces Intention to Revise Name...  \n",
       "3  Petrus Resources Announces Implementation of D...  \n",
       "4  NioBay Announces a New Member to Its Board of ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(filtered_news_df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.globenewswire.com/news-release/2024/11/28/2988905/0/en/Middlefield-Announces-Intention-to-Revise-Names-and-Reduce-ESG-Limitations-for-Two-ETFs.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['link'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date                                               link  \\\n",
      "0  2024-11-27T22:32:30Z  https://www.investing.com/news/press-releases/...   \n",
      "1  2024-11-27T22:29:07Z  https://erickimphotography.com/blog/2024/11/27...   \n",
      "2  2024-11-27T22:28:00Z  https://sputnikglobe.com/20241127/crypto-leade...   \n",
      "3  2024-11-27T22:19:30Z  https://erickimphotography.com/blog/2024/11/27...   \n",
      "4  2024-11-27T22:14:55Z  http://www.etf.com/sections/news/microstrategy...   \n",
      "\n",
      "                                                text  \n",
      "0  Simplify Provides Estimated Capital Gain Distr...  \n",
      "1  More Dynamic Aesthetics The upside of a pearl ...  \n",
      "2  Crypto Leaders Urging Trump to Create Federal ...  \n",
      "3  F.U.T.W.! FUTW! Fuck Up the World! Fuck up the...  \n",
      "4  MicroStrategy 2X ETF Adds Options Amid Crypto ...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Step 1: Set your News API key\n",
    "api_key = 'd78f0a5978844825bbe9414dcf9234d9'  # Replace with your News API key\n",
    "\n",
    "# Step 2: Define the function to fetch news\n",
    "def fetch_news(topic, days):\n",
    "    \"\"\"\n",
    "    Fetch news related to a specific topic using News API and filter by date.\n",
    "    \n",
    "    :param topic: The keyword or topic to search for (e.g., \"Bitcoin\").\n",
    "    :param days: Number of previous days to filter the news.\n",
    "    :return: A DataFrame containing the news data with date, link, and text.\n",
    "    \"\"\"\n",
    "    # Calculate the date 'days' ago from today\n",
    "    from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Define the API endpoint and parameters\n",
    "    url = 'https://newsapi.org/v2/everything'\n",
    "    params = {\n",
    "        'q': topic,\n",
    "        'from': from_date,\n",
    "        'sortBy': 'publishedAt',\n",
    "        'apiKey': api_key,\n",
    "        'language': 'en',\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Convert the 'articles' key in the JSON response to a pandas DataFrame\n",
    "        if 'articles' in data:\n",
    "            articles = data['articles']\n",
    "            news_data = []\n",
    "            for article in articles:\n",
    "                news_data.append({\n",
    "                    'date': article['publishedAt'],\n",
    "                    'link': article['url'],\n",
    "                    'text': article['title'] + \" \" + article['description'] if article['description'] else article['title']\n",
    "                })\n",
    "            news_df = pd.DataFrame(news_data)\n",
    "            return news_df\n",
    "        else:\n",
    "            print(\"No news data found for this topic.\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Step 3: Fetch news data for a specific topic\n",
    "topic = \"Bitcoin\"  # Replace with your topic of interest\n",
    "days = 7  # Replace with the number of previous days to filter\n",
    "news_df = fetch_news(topic, days)\n",
    "\n",
    "# Step 4: Display the news DataFrame\n",
    "if not news_df.empty:\n",
    "    print(news_df.head())\n",
    "else:\n",
    "    print(\"No data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.benzinga.com/news/global/24/12/42305773/key-stocks-etf-to-watch-as-french-government-faces-no-confidence-vote'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(filtered_news_df)\n",
    "df.head()\n",
    "df['link'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xerox Holdings Corporation Investors: Please contact the Portnoy Law Firm to recover your losses. January 21, 2025 Deadline to file Lead Plaintiff Motion - Xerox Holdings  ( NASDAQ:XRX ) '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date                                               link  \\\n",
      "0  2024-12-03 23:48:24  https://www.benzinga.com/news/global/24/12/423...   \n",
      "1  2024-12-03 23:43:43  https://decrypt.co/294645/bitcoin-altcoins-dog...   \n",
      "2  2024-12-03 23:41:27  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "3  2024-12-03 23:36:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "4  2024-12-03 23:35:48  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "5  2024-12-03 23:30:07  https://www.scmp.com/business/banking-finance/...   \n",
      "6  2024-12-03 23:30:00  https://www.globenewswire.com/news-release/202...   \n",
      "7  2024-12-03 23:22:00  https://www.fool.com/investing/2024/12/03/why-...   \n",
      "8  2024-12-03 23:19:10  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "9  2024-12-03 23:14:00  https://www.globenewswire.com/news-release/202...   \n",
      "10 2024-12-03 23:13:39  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "11 2024-12-03 23:13:00  https://www.fool.com/investing/2024/12/03/why-...   \n",
      "12 2024-12-03 23:13:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "13 2024-12-03 23:09:16  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "14 2024-12-03 23:09:07  https://www.benzinga.com/general/social-media/...   \n",
      "15 2024-12-03 23:09:00  https://www.globenewswire.com/news-release/202...   \n",
      "16 2024-12-03 23:06:22  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "17 2024-12-03 23:06:00  https://www.globenewswire.com/news-release/202...   \n",
      "18 2024-12-03 23:04:53  https://decrypt.co/294635/illuvium-ethereum-ga...   \n",
      "19 2024-12-03 23:00:32  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "20 2024-12-03 23:00:00  https://www.globenewswire.com/news-release/202...   \n",
      "21 2024-12-03 22:58:44  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "22 2024-12-03 22:58:32  https://www.benzinga.com/general/gaming/24/12/...   \n",
      "23 2024-12-03 22:53:00  https://www.globenewswire.com/news-release/202...   \n",
      "24 2024-12-03 22:49:03  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "25 2024-12-03 22:48:38  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "26 2024-12-03 22:47:21  https://decrypt.co/294632/grayscale-files-to-c...   \n",
      "27 2024-12-03 22:41:59  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "28 2024-12-03 22:41:16  https://www.benzinga.com/general/entertainment...   \n",
      "29 2024-12-03 22:41:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "30 2024-12-03 22:41:00  https://www.globenewswire.com/news-release/202...   \n",
      "31 2024-12-03 22:40:00  https://www.globenewswire.com/news-release/202...   \n",
      "32 2024-12-03 22:32:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "33 2024-12-03 22:31:20  https://www.fool.com/investing/2024/12/03/3-re...   \n",
      "34 2024-12-03 22:30:13  https://www.cnbc.com/2024/12/03/florida-prison...   \n",
      "35 2024-12-03 22:30:00  https://www.globenewswire.com/news-release/202...   \n",
      "36 2024-12-03 22:30:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "37 2024-12-03 22:27:00  https://www.benzinga.com/pressreleases/24/12/n...   \n",
      "38 2024-12-03 22:21:16  https://www.benzinga.com/markets/cryptocurrenc...   \n",
      "39 2024-12-03 22:18:16  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "40 2024-12-03 22:18:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "41 2024-12-03 22:18:00  https://www.globenewswire.com/news-release/202...   \n",
      "42 2024-12-03 22:06:00  https://www.benzinga.com/pressreleases/24/12/n...   \n",
      "43 2024-12-03 22:05:00  https://www.globenewswire.com/news-release/202...   \n",
      "44 2024-12-03 22:05:00  https://www.globenewswire.com/news-release/202...   \n",
      "45 2024-12-03 22:04:00  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "46 2024-12-03 22:04:00  https://www.globenewswire.com/news-release/202...   \n",
      "47 2024-12-03 22:03:21  https://www.benzinga.com/pressreleases/24/12/g...   \n",
      "48 2024-12-03 22:03:00  https://www.globenewswire.com/news-release/202...   \n",
      "49 2024-12-03 22:00:30  https://www.benzinga.com/general/space/24/12/4...   \n",
      "\n",
      "                                                 text  \\\n",
      "0   Key Stocks, ETF To Watch As French Government ...   \n",
      "1   As Bitcoin Hovers Around Its All-Time High, Tr...   \n",
      "2   Xerox Holdings Corporation Investors: Please c...   \n",
      "3   ROSEN, LEADING INVESTOR COUNSEL, Encourages Cu...   \n",
      "4   Quanterix Corporation Investors: Company Inves...   \n",
      "5   China M&A deal volume to bottom out this year,...   \n",
      "6   American Hotel Income Properties REIT LP Annou...   \n",
      "7                   Why Accenture Stock Slumped Today   \n",
      "8   Robbins LLP Urges XRX Stockholders with Large ...   \n",
      "9   Dominion Lending Centres Inc. Receives Shareho...   \n",
      "10  Customers Bancorp, Inc. Investors: Please cont...   \n",
      "11  Why Trump Media and Technology Stock Slipped 1...   \n",
      "12  ROSEN, THE FIRST FILING FIRM, Encourages Visa ...   \n",
      "13  Skyharbour Announces Upsized Private Placement...   \n",
      "14  Threads Takes On X, Bluesky With New Search Op...   \n",
      "15  Skyharbour Announces Upsized Private Placement...   \n",
      "16  Robbins LLP Urges WOLF Stockholders with Large...   \n",
      "17  POET Technologies Completes US$25 Million Regi...   \n",
      "18  'Illuvium Beyond' Ethereum Game Reveals Casio ...   \n",
      "19  Gatos Silver Announces Date of Special Meeting...   \n",
      "20  Gatos Silver Announces Date of Special Meeting...   \n",
      "21  Dentsply Sirona, Inc. Investors: Please contac...   \n",
      "22  Gamers Now Watch More Than They Play - How Pub...   \n",
      "23  Sprott Focus Trust, Inc.  ( Nasdaq-FUND )  Dec...   \n",
      "24  Robbins LLP Urges V Stockholders with Large Lo...   \n",
      "25  Robbins LLP Urges PACS Stockholders with Large...   \n",
      "26  Grayscale Files to Convert Solana Trust into E...   \n",
      "27  Algoma Steel Group to Participate in the Inaug...   \n",
      "28  'Squid Game' Season 2 Includes New Games, Cont...   \n",
      "29  ROSEN, TOP-RANKED INVESTOR COUNSEL, Encourages...   \n",
      "30  Algoma Steel Group to Participate in the Inaug...   \n",
      "31  Eagle Bancorp, Inc. Announces Registered Excha...   \n",
      "32  ROSEN, SKILLED INVESTOR COUNSEL, Encourages Ch...   \n",
      "33  3 Reasons to Buy Nvidia Stock as the UBS Globa...   \n",
      "34  Florida woman who led $200 million Ponzi schem...   \n",
      "35  Brookfield Commits to Growing Investment in Fr...   \n",
      "36  Brookfield Commits to Growing Investment in Fr...   \n",
      "37  Regal Cineworld Announces Refinancing of Term ...   \n",
      "38  Bitcoin, Ethereum, Dogecoin Hold Steady, Trade...   \n",
      "39  Procaps Group Announces Financing, Shareholder...   \n",
      "40  ACHC DEADLINE NOTICE: ROSEN, A GLOBAL AND LEAD...   \n",
      "41  Procaps Group Announces Financing, Shareholder...   \n",
      "42  Ticket Market to grow by USD 228.52 billion  (...   \n",
      "43  Ready Capital Corporation Announces Pricing of...   \n",
      "44  Diversified Royalty Corp. Announces December 2...   \n",
      "45  Tavia Acquisition Corp. Announces Pricing of $...   \n",
      "46  Tavia Acquisition Corp. Announces Pricing of $...   \n",
      "47  Navitas Semiconductor Appoints Dr. Ranbir Sing...   \n",
      "48  Navitas Semiconductor Appoints Dr. Ranbir Sing...   \n",
      "49  Intuitive Machines Stock Falls After Hours: He...   \n",
      "\n",
      "                                            full_text  \n",
      "0   French Prime Minister Michel Barnier faces a c...  \n",
      "1   As Bitcoin Hovers Around Its All-Time High, Tr...  \n",
      "2   Investors can contact the law firm at no cost ...  \n",
      "3   NEW YORK, Dec.  03, 2024  (GLOBE NEWSWIRE) -- ...  \n",
      "4   Investors can contact the law firm at no cost ...  \n",
      "5   UBS says China M&A deal volume fell 10 per cen...  \n",
      "6   \\n\\n\\nDecember 03, 2024 18:30 ET\\n\\n\\r\\n      ...  \n",
      "7   Founded in 1993, The Motley Fool is a financia...  \n",
      "8   SAN DIEGO, Dec.  03, 2024  (GLOBE NEWSWIRE) --...  \n",
      "9   \\n\\n\\nDecember 03, 2024 18:14 ET\\n\\n\\r\\n      ...  \n",
      "10  Investors can contact the law firm at no cost ...  \n",
      "11  Founded in 1993, The Motley Fool is a financia...  \n",
      "12  NEW YORK, Dec.  03, 2024  (GLOBE NEWSWIRE) -- ...  \n",
      "13  Not For Distribution to U.S. News Wire Service...  \n",
      "14  Social media platform Threads, which is a part...  \n",
      "15  \\n\\n\\nDecember 03, 2024 18:09 ET\\n\\n\\r\\n      ...  \n",
      "16  SAN DIEGO, Dec.  03, 2024  (GLOBE NEWSWIRE) --...  \n",
      "17  \\n\\n\\nDecember 03, 2024 18:06 ET\\n\\n\\r\\n      ...  \n",
      "18  'Illuvium Beyond' Ethereum Game Reveals Casio ...  \n",
      "19  VANCOUVER, British Columbia, Dec.  03, 2024  (...  \n",
      "20  \\n\\n\\nDecember 03, 2024 18:00 ET\\n\\n\\r\\n      ...  \n",
      "21  LOS ANGELES, Dec.  03, 2024  (GLOBE NEWSWIRE) ...  \n",
      "22  Gamers are spending more time watching gaming ...  \n",
      "23  \\n\\n\\nDecember 03, 2024 17:53 ET\\n\\n\\r\\n      ...  \n",
      "24  SAN DIEGO, Dec.  03, 2024  (GLOBE NEWSWIRE) --...  \n",
      "25  SAN DIEGO, Dec.  03, 2024  (GLOBE NEWSWIRE) --...  \n",
      "26  Grayscale Files to Convert Solana Trust into E...  \n",
      "27  SAULT STE. MARIE, Ontario, Dec.  03, 2024  (GL...  \n",
      "28  Streaming giant Netflix Inc NFLX is set to rel...  \n",
      "29  NEW YORK, Dec.  03, 2024  (GLOBE NEWSWIRE) -- ...  \n",
      "30  \\n\\n\\nDecember 03, 2024 17:41 ET\\n\\n\\r\\n      ...  \n",
      "31  \\n\\n\\nDecember 03, 2024 17:40 ET\\n\\n\\r\\n      ...  \n",
      "32  NEW YORK, Dec.  03, 2024  (GLOBE NEWSWIRE) -- ...  \n",
      "33  Founded in 1993, The Motley Fool is a financia...  \n",
      "34  Credit Cards Loans Banking Mortgages Insurance...  \n",
      "35  \\n\\n\\nDecember 03, 2024 17:30 ET\\n\\n\\r\\n      ...  \n",
      "36  New office hub opened in ParisRenewable energy...  \n",
      "37  The refinancing follows record highs for Regal...  \n",
      "38  Cryptocurrency markets are trading lower on Tu...  \n",
      "39  MIAMI and BARRANQUILLA, Colombia , Dec.  03, 2...  \n",
      "40  NEW YORK, Dec.  03, 2024  (GLOBE NEWSWIRE) -- ...  \n",
      "41  \\n\\n\\nDecember 03, 2024 17:18 ET\\n\\n\\r\\n      ...  \n",
      "42  NEW YORK, Dec. 3, 2024 /PRNewswire/ -- Report ...  \n",
      "43  \\n\\n\\nDecember 03, 2024 17:05 ET\\n\\n\\r\\n      ...  \n",
      "44  \\n\\n\\nDecember 03, 2024 17:05 ET\\n\\n\\r\\n      ...  \n",
      "45  London, United Kingdom, Dec.  03, 2024  (GLOBE...  \n",
      "46  \\n\\n\\nDecember 03, 2024 17:04 ET\\n\\n\\r\\n      ...  \n",
      "47  TORRANCE, Calif., Dec.  03, 2024  (GLOBE NEWSW...  \n",
      "48  \\n\\n\\nDecember 03, 2024 17:03 ET\\n\\n\\r\\n      ...  \n",
      "49  Intuitive Machines Inc LUNR shares are trading...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Alpha Vantage API key\n",
    "api_key = \"8USSUHG9CIPYSADT\"  # Replace with your Alpha Vantage API key\n",
    "\n",
    "# Function to fetch and filter news\n",
    "def fetch_filtered_news_with_full_text(topic, days):\n",
    "    \"\"\"\n",
    "    Fetch news related to a specific topic using Alpha Vantage API and filter by date,\n",
    "    then fetch the full text of each article.\n",
    "    \n",
    "    :param topic: The keyword or topic to search for (e.g., \"Bitcoin\", \"Amazon\").\n",
    "    :param days: Number of previous days to filter the news.\n",
    "    :return: A DataFrame containing filtered news with date, link, and full text.\n",
    "    \"\"\"\n",
    "    # Define the API endpoint and parameters\n",
    "    url = f\"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"keywords\": topic,\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"feed\" in data:\n",
    "            news_df = pd.DataFrame(data[\"feed\"])\n",
    "            news_df = news_df.rename(columns={\"time_published\": \"date\", \"url\": \"link\", \"title\": \"text\"})\n",
    "            news_df = news_df[[\"date\", \"link\", \"text\"]]\n",
    "            news_df[\"date\"] = pd.to_datetime(news_df[\"date\"], format=\"%Y%m%dT%H%M%S\")\n",
    "            \n",
    "            # Filter rows by the specified number of previous days\n",
    "            cutoff_date = datetime.now() - timedelta(days=days)\n",
    "            filtered_df = news_df[news_df[\"date\"] >= cutoff_date]\n",
    "            \n",
    "            # Fetch full text for each article\n",
    "            filtered_df[\"full_text\"] = filtered_df[\"link\"].apply(fetch_article_text)\n",
    "            return filtered_df\n",
    "        else:\n",
    "            print(\"No news data found for this topic.\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to fetch full article text\n",
    "def fetch_article_text(url):\n",
    "    \"\"\"\n",
    "    Fetch the full text of an article from its URL.\n",
    "    \n",
    "    :param url: The URL of the article.\n",
    "    :return: The full text of the article or None if not accessible.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            paragraphs = soup.find_all('p')\n",
    "            full_text = ' '.join([para.get_text() for para in paragraphs if para.get_text()])\n",
    "            return full_text\n",
    "        else:\n",
    "            print(f\"Failed to fetch article content from {url}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching article content from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch and filter news with full text\n",
    "topic = \"Tesla\"  # Replace with your topic of interest\n",
    "days = 7  # Replace with the number of previous days to filter\n",
    "filtered_news_df = fetch_filtered_news_with_full_text(topic, days)\n",
    "\n",
    "# Display the filtered news DataFrame\n",
    "if not filtered_news_df.empty:\n",
    "    print(filtered_news_df)\n",
    "else:\n",
    "    print(\"No data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.shortcuts import render\n",
    "from django.contrib.auth.models import User\n",
    "from rest_framework import generics\n",
    "from rest_framework.response import Response\n",
    "from rest_framework.views import APIView\n",
    "from .serializers import UserSerializer\n",
    "from rest_framework.permissions import IsAuthenticated, AllowAny\n",
    "from rest_framework import viewsets, status\n",
    "from rest_framework.response import Response\n",
    "from rest_framework.decorators import action\n",
    "from .models import UserInterest, ArticleData\n",
    "from .serializers import UserInterestSerializer, ArticleDataSerializer\n",
    "from .scraper import scrape_articles\n",
    "from django.utils.timezone import now\n",
    "import json\n",
    "import logging\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from rest_framework.decorators import api_view\n",
    "from django.http import JsonResponse\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from django.db.models import Avg\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CreateUserView(generics.CreateAPIView):\n",
    "    queryset = User.objects.all()\n",
    "    serializer_class = UserSerializer\n",
    "    permission_classes = [AllowAny]\n",
    "\n",
    "\n",
    "\n",
    "class UserDetailView(APIView):\n",
    "    permission_classes = [IsAuthenticated]\n",
    "\n",
    "    def get(self, request):\n",
    "        user = request.user\n",
    "        return Response({\n",
    "            'id': user.id,\n",
    "            'username': user.username\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from django.utils.timezone import now\n",
    "\n",
    "class UserInterestViewSet(viewsets.ModelViewSet):\n",
    "    queryset = UserInterest.objects.all()\n",
    "    serializer_class = UserInterestSerializer\n",
    "    permission_classes = [IsAuthenticated]  # Ensure only authenticated users can create interests\n",
    "\n",
    "    def create(self, request, *args, **kwargs):\n",
    "        data = request.data.copy()\n",
    "        data['user'] = request.user.id  # Automatically assign the authenticated user\n",
    "\n",
    "        serializer = self.get_serializer(data=data)\n",
    "        serializer.is_valid(raise_exception=True)\n",
    "        self.perform_create(serializer)\n",
    "        headers = self.get_success_headers(serializer.data)\n",
    "        return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers)\n",
    "\n",
    "    @action(detail=True, methods=['post'])\n",
    "    def run_scraper(self, request, pk=None):\n",
    "        user_interest = self.get_object()\n",
    "        company_name = user_interest.company_name\n",
    "\n",
    "        # Delete existing articles for the user's interest\n",
    "        ArticleData.objects.filter(interest=user_interest).delete()\n",
    "\n",
    "        # Fetch articles\n",
    "        articles = scrape_articles(company_name, days=7)\n",
    "\n",
    "        # Save articles to the database\n",
    "        for article in articles:\n",
    "            ArticleData.objects.create(\n",
    "                interest=user_interest,\n",
    "                link=article['link'],\n",
    "                date=datetime.fromisoformat(article['date']).date(),\n",
    "                text=article['text'],\n",
    "                source=article['source']  # Save the source field\n",
    "            )\n",
    "\n",
    "        return Response({\"message\": \"Articles scraped and saved successfully.\"}, status=status.HTTP_201_CREATED)\n",
    "\n",
    "            \n",
    "\n",
    "class ArticleDataViewSet(viewsets.ReadOnlyModelViewSet):\n",
    "    queryset = ArticleData.objects.all()\n",
    "    serializer_class = ArticleDataSerializer\n",
    "\n",
    "nltk.download('vader_lexicon')  # Download sentiment analysis data\n",
    "\n",
    "\n",
    "@api_view(['GET'])\n",
    "def generate_wordcloud_and_sentiment(request, interest_id):\n",
    "    try:\n",
    "        source = request.query_params.get('source', None)\n",
    "\n",
    "        # Filter articles\n",
    "        if source:\n",
    "            articles = ArticleData.objects.filter(interest_id=interest_id, source=source)\n",
    "        else:\n",
    "            articles = ArticleData.objects.filter(interest_id=interest_id)\n",
    "\n",
    "        if not articles.exists():\n",
    "            return JsonResponse({\"error\": \"No articles found for this interest.\"}, status=404)\n",
    "\n",
    "        # Aggregate sentiment scores by date\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        sentiment_by_date = {}\n",
    "        for article in articles:\n",
    "            sentiment = sia.polarity_scores(article.text)\n",
    "            date = article.date\n",
    "            if date not in sentiment_by_date:\n",
    "                sentiment_by_date[date] = {'pos': [], 'neu': [], 'neg': []}\n",
    "            sentiment_by_date[date]['pos'].append(sentiment['pos'])\n",
    "            sentiment_by_date[date]['neu'].append(sentiment['neu'])\n",
    "            sentiment_by_date[date]['neg'].append(sentiment['neg'])\n",
    "\n",
    "        # Calculate averages\n",
    "        sentiment_series = [\n",
    "            {\n",
    "                \"date\": date,\n",
    "                \"pos\": sum(scores['pos']) / len(scores['pos']),\n",
    "                \"neu\": sum(scores['neu']) / len(scores['neu']),\n",
    "                \"neg\": sum(scores['neg']) / len(scores['neg']),\n",
    "            }\n",
    "            for date, scores in sentiment_by_date.items()\n",
    "        ]\n",
    "\n",
    "        return JsonResponse({\"sentiment_series\": sentiment_series})\n",
    "    except Exception as e:\n",
    "        return JsonResponse({\"error\": str(e)}, status=500)\n",
    "\n",
    "@api_view(['GET'])\n",
    "def get_sources(request):\n",
    "    sources = ArticleData.objects.values_list('source', flat=True).distinct()\n",
    "    return JsonResponse(list(sources), safe=False)\n",
    "@api_view(['GET'])\n",
    "def sentiment_time_series(request, interest_id):\n",
    "    try:\n",
    "        source = request.GET.get('source', None)\n",
    "\n",
    "        # Filter articles by interest and source\n",
    "        articles = ArticleData.objects.filter(interest_id=interest_id)\n",
    "        if source:\n",
    "            articles = articles.filter(source=source)\n",
    "\n",
    "        if not articles.exists():\n",
    "            return JsonResponse({\"error\": \"No articles found for this interest.\"}, status=404)\n",
    "\n",
    "        # Perform sentiment analysis grouped by date\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        sentiment_by_date = {}\n",
    "        for article in articles:\n",
    "            sentiment = sia.polarity_scores(article.text)\n",
    "            date = article.date\n",
    "            if date not in sentiment_by_date:\n",
    "                sentiment_by_date[date] = {\"pos\": [], \"neu\": [], \"neg\": []}\n",
    "            sentiment_by_date[date][\"pos\"].append(sentiment[\"pos\"])\n",
    "            sentiment_by_date[date][\"neu\"].append(sentiment[\"neu\"])\n",
    "            sentiment_by_date[date][\"neg\"].append(sentiment[\"neg\"])\n",
    "\n",
    "        # Aggregate sentiment scores for each date\n",
    "        result = [\n",
    "            {\n",
    "                \"date\": date,\n",
    "                \"pos\": sum(values[\"pos\"]) / len(values[\"pos\"]),\n",
    "                \"neu\": sum(values[\"neu\"]) / len(values[\"neu\"]),\n",
    "                \"neg\": sum(values[\"neg\"]) / len(values[\"neg\"]),\n",
    "            }\n",
    "            for date, values in sentiment_by_date.items()\n",
    "        ]\n",
    "\n",
    "        # Sort results by date\n",
    "        result.sort(key=lambda x: x[\"date\"])\n",
    "\n",
    "        return JsonResponse(result, safe=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        return JsonResponse({\"error\": str(e)}, status=500)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
